//  For licensing see accompanying LICENSE.md file.
//  Copyright Â© 2025 Cription. All rights reserved.

import Foundation
import SwiftUI
import WhisperKit
import Security
import AVFoundation

// MARK: - TranCription Service Manager

@MainActor
class TranCriptionServiceManager: ObservableObject {
    @Published var isProcessing = false
    @Published var progress: Double = 0.0
    @Published var status: String = ""
    @Published var error: String?
    @Published var showingCreditPurchaseSheet = false
    @Published var showingTokenLimitPrompt = false
    @Published var enableAudioOptimization = true  // éŸ³å£°æœ€é©åŒ–ã‚’æœ‰åŠ¹åŒ–ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ONï¼‰
    
    // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”¨
    @Published var isRecording = false
    @Published var isTranscribing = false
    @Published var realtimeText: String = ""
    @Published var bufferSeconds: Double = 0.0
    
    private var whisperModelManager: WhisperModelManager?
    private var openAIService: OpenAITranCriptionService?
    private var textTranslationService: OpenAITextTranslationService?
    var openAIRealtimeService: OpenAIRealtimeTranscriptionService?
    var openAIStreamingService: OpenAIStreamingTranscriptionService?
    var fireworksStreamingService: FireworksStreamingASRService?
    var fireworksServerlessService: FireworksServerlessASRService?
    var parakeetService: ParakeetTranscriptionService?
    private var tranCriptionTask: Task<Void, Never>?
    private var lastBufferSize: Int = 0
    
    init() {
        // Load API key from Keychain on initialization
        loadAPIKeyFromKeychain()
        
        // Initialize Parakeet service
        parakeetService = ParakeetTranscriptionService()
        
        // ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã®æ›´æ–°ã‚’ç›£è¦–
        Task {
            await SubCriptionManager.shared.updateTokenLimitForSubscription()
        }
    }
    
    func setWhisperModelManager(_ modelManager: WhisperModelManager) {
        self.whisperModelManager = modelManager
    }
    
    // MARK: - API Key Management
    
    func updateAPIKey(_ apiKey: String) {
        if !apiKey.isEmpty {
            // Save to Keychain using SecureKeychainManager
            if SecureKeychainManager.shared.saveAPIKey(apiKey) {
                openAIService = OpenAITranCriptionService(apiKey: apiKey)
                textTranslationService = OpenAITextTranslationService(apiKey: apiKey)
                openAIRealtimeService = OpenAIRealtimeTranscriptionService(apiKey: apiKey)
                openAIStreamingService = OpenAIStreamingTranscriptionService(apiKey: apiKey)
                print("âœ… OpenAI API key updated and saved to Keychain")
            } else {
                print("âŒ Failed to save OpenAI API key to Keychain")
                openAIService = nil
                textTranslationService = nil
                openAIRealtimeService = nil
                openAIStreamingService = nil
            }
        } else {
            openAIService = nil
            textTranslationService = nil
            openAIRealtimeService = nil
            openAIStreamingService = nil
            print("âœ… OpenAI API key removed")
        }
    }
    
    func updateFireworksAPIKey(_ apiKey: String) {
        if !apiKey.isEmpty {
            // Save to Keychain using SecureKeychainManager
            if SecureKeychainManager.shared.saveFireworksAPIKey(apiKey) {
                fireworksStreamingService = FireworksStreamingASRService(apiKey: apiKey)
                fireworksServerlessService = FireworksServerlessASRService(apiKey: apiKey)
                print("âœ… Fireworks API key updated and saved to Keychain")
            } else {
                print("âŒ Failed to save Fireworks API key to Keychain")
                fireworksStreamingService = nil
                fireworksServerlessService = nil
            }
        } else {
            fireworksStreamingService = nil
            fireworksServerlessService = nil
            print("âœ… Fireworks API key removed")
        }
    }
    
    func hasValidAPIKey() -> Bool {
        return openAIService != nil
    }
    
    func hasValidFireworksAPIKey() -> Bool {
        return fireworksStreamingService != nil || fireworksServerlessService != nil
    }
    
    func clearAPIKey() {
        SecureKeychainManager.shared.deleteAPIKey()
        openAIService = nil
        textTranslationService = nil
        openAIRealtimeService = nil
        openAIStreamingService = nil
        print("âœ… OpenAI API key cleared from Keychain")
    }
    
    func clearFireworksAPIKey() {
        SecureKeychainManager.shared.deleteFireworksAPIKey()
        fireworksStreamingService = nil
        fireworksServerlessService = nil
        print("âœ… Fireworks API key cleared from Keychain")
    }
    
    // MARK: - API Key Loading from Keychain
    
    func loadAPIKeyFromKeychain() {
        print("ğŸ” Attempting to load API keys from Keychain...")
        
        // Load OpenAI API key
        if let apiKey = SecureKeychainManager.shared.loadAPIKey(), !apiKey.isEmpty {
            print("âœ… OpenAI API key loaded successfully from Keychain, updating TranCriptionServiceManager")
            openAIService = OpenAITranCriptionService(apiKey: apiKey)
            textTranslationService = OpenAITextTranslationService(apiKey: apiKey)
            openAIRealtimeService = OpenAIRealtimeTranscriptionService(apiKey: apiKey)
            openAIStreamingService = OpenAIStreamingTranscriptionService(apiKey: apiKey)
        } else {
            print("âŒ No OpenAI API key found in Keychain - user needs to set one in settings")
            openAIService = nil
            textTranslationService = nil
            openAIRealtimeService = nil
            openAIStreamingService = nil
        }
        
        // Load Fireworks API key
        if let fireworksAPIKey = SecureKeychainManager.shared.loadFireworksAPIKey(), !fireworksAPIKey.isEmpty {
            print("âœ… Fireworks API key loaded successfully from Keychain, updating TranCriptionServiceManager")
            fireworksStreamingService = FireworksStreamingASRService(apiKey: fireworksAPIKey)
            fireworksServerlessService = FireworksServerlessASRService(apiKey: fireworksAPIKey)
        } else {
            print("âŒ No Fireworks API key found in Keychain - user needs to set one in settings")
            fireworksStreamingService = nil
            fireworksServerlessService = nil
        }
    }
    
    private func hasAPIKeyInKeychain() -> Bool {
        return SecureKeychainManager.shared.hasAPIKey()
    }
    
    private func hasFireworksAPIKeyInKeychain() -> Bool {
        return SecureKeychainManager.shared.hasFireworksAPIKey()
    }
    
    // MARK: - Public Methods
    
    func transcriptionAudio(audioData: Data, language: String? = nil, customPrompt: String? = nil) async throws -> TranCriptionResult {
        guard !isProcessing else {
            throw TranCriptionError.alreadyProcessing
        }
        
        isProcessing = true
        progress = 0.0
        status = "Preparing tranCription..."
        error = nil
        
        defer {
            isProcessing = false
            progress = 0.0
            status = ""
        }
        
        do {
            // ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ï¼ˆ25MBåˆ¶é™ï¼‰
            let maxFileSize = 25 * 1024 * 1024 // 25MB
            guard audioData.count <= maxFileSize else {
                throw TranCriptionError.fileTooLarge
            }
            
            // éŸ³å£°æœ€é©åŒ–ã‚’é©ç”¨ï¼ˆæœ‰åŠ¹åŒ–ã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
            var optimizedAudioData = audioData
            if enableAudioOptimization {
                status = "Optimizing audio..."
                progress = 0.05
                
                do {
                    // ç„¡éŸ³å‰Šé™¤ã‚’è©¦ã¿ã‚‹
                    let silenceRemoved = try await AudioOptimizer.removeSilence(from: audioData)
                    optimizedAudioData = silenceRemoved
                    
                    print("âœ… Audio optimization completed")
                } catch {
                    // æœ€é©åŒ–ãŒå¤±æ•—ã—ã¦ã‚‚å…ƒã®ãƒ‡ãƒ¼ã‚¿ã§ç¶šè¡Œ
                    print("âš ï¸ Audio optimization failed, using original data: \(error)")
                }
            }
            
            // é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã«åŸºã¥ã„ã¦é©åˆ‡ãªã‚µãƒ¼ãƒ“ã‚¹ã‚’é¸æŠ
            guard let whisperModelManager = whisperModelManager else {
                throw TranCriptionError.whisperModelManagerNotAvailable
            }
            let selectedModel = whisperModelManager.selectedModel
            
            // ã‚³ã‚¹ãƒˆå‰Šæ¸›: ã‚½ãƒ¼ã‚¹è¨€èªãŒè‹±èªã§ãƒ•ã‚¡ã‚¤ãƒ«å…¥åŠ›ã®å ´åˆã€OpenAIãƒ¢ãƒ‡ãƒ«ãŒé¸æŠã•ã‚Œã¦ã„ã¦ã‚‚ãƒãƒ³ãƒ‰ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
            // ãŸã ã—ã€autodetectãŒé¸æŠã•ã‚ŒãŸå ´åˆã¯å¿…ãšOpenAIãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
            let shouldUseLocalModel = isOpenAIModel(selectedModel) && 
                                     (language == "en" || language == "english") &&
                                     language != "auto"
            
            if shouldUseLocalModel {
                // è‹±èªã®ãƒ•ã‚¡ã‚¤ãƒ«å…¥åŠ›ã®å ´åˆã€ãƒãƒ³ãƒ‰ãƒ«ãƒ¢ãƒ‡ãƒ«ã§å‡¦ç†
                print("ğŸ”µ Cost optimization: Using local model for English file input instead of OpenAI")
                
                guard let whisperKit = whisperModelManager.whisperKit else {
                    throw TranCriptionError.whisperKitNotAvailable
                }
                
                status = "Using local model for English tranCription..."
                progress = 0.2
                
                let result = try await performWhisperKitTranCription(
                    audioData: optimizedAudioData,
                    language: language,
                    whisperKit: whisperKit
                )
                
                status = "TranCription completed!"
                progress = 1.0
                
                return result
                
            } else if isParakeetModel(selectedModel) {
                // Parakeetãƒ¢ãƒ‡ãƒ«ã®å ´åˆ
                guard let parakeetService = parakeetService else {
                    throw TranCriptionError.whisperKitNotAvailable
                }
                
                status = "Using Parakeet tranCription..."
                progress = 0.2
                
                // Parakeetã‚µãƒ¼ãƒ“ã‚¹ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ãªã„å ´åˆã¯åˆæœŸåŒ–
                if !parakeetService.isInitialized {
                    status = "Initializing Parakeet model..."
                    progress = 0.1
                    
                    let modelVersion: AsrModelVersion = selectedModel.contains("v2") ? .v2 : .v3
                    try await parakeetService.initialize(modelVersion: modelVersion)
                }
                
                // éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚µãƒ³ãƒ—ãƒ«é…åˆ—ã«å¤‰æ›
                let samples = try await convertAudioDataToSamples(optimizedAudioData)
                
                // Parakeetã§ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒ©ã‚¤ãƒ–
                let parakeetResult = try await parakeetService.transcribe(audioSamples: samples)
                
                // Criptionå½¢å¼ã«å¤‰æ›
                let result = parakeetResult.toCriptionTranscriptionResult()
                
                status = "TranCription completed!"
                progress = 1.0
                
                return TranCriptionResult(
                    text: result.text,
                    segments: result.segments,
                    language: result.language,
                    duration: result.duration
                )
                
            } else if isOpenAIModel(selectedModel) {
                // OpenAIãƒ¢ãƒ‡ãƒ«ã®å ´åˆ
                if language == "auto" {
                    print("ğŸ”µ Auto-detect selected: Forcing OpenAI model usage for language detection")
                }
                guard let openAIService = openAIService else {
                    print("âŒ OpenAI service not available - attempting to reload API key from Keychain")
                    loadAPIKeyFromKeychain()
                    
                    guard let retryOpenAIService = openAIService else {
                        print("âŒ OpenAI service still not available after reload attempt")
                        // Check if API key exists in Keychain to provide better error message
                        if hasAPIKeyInKeychain() {
                            throw TranCriptionError.openAIServiceNotAvailable
                        } else {
                            throw TranCriptionError.openAIAPIKeyNotSet
                        }
                    }
                    
                    // Retry with the reloaded service
                    status = "Using OpenAI tranCription (retry)..."
                    progress = 0.2
                    
                    let finalLanguage = (language == "auto") ? nil : language
                    
                    let result = try await retryOpenAIService.transcriptionAudio(
                        audioData: optimizedAudioData,
                        language: finalLanguage,
                        model: selectedModel,
                        customPrompt: customPrompt
                    )
                    
                    status = "TranCription completed!"
                    progress = 1.0
                    
                    return result
                }
                
                status = "Using OpenAI tranCription..."
                progress = 0.2
                
                do {
                    // è¨€èªãŒ"auto"ã®å ´åˆã¯nilã«ã—ã¦è‡ªå‹•æ¤œå‡ºã‚’æœ‰åŠ¹åŒ–
                    let finalLanguage = (language == "auto") ? nil : language
                    
                    print("ğŸ”µ TranscriptionServiceManager: Calling OpenAI transcription")
                    if let lang = language {
                        print("   - Input language: '\(lang)'")
                    } else {
                        print("   - Input language: nil")
                    }
                    if let finalLang = finalLanguage {
                        print("   - Final language: '\(finalLang)' (will be sent to API)")
                    } else {
                        print("   - Final language: nil (auto-detect mode - no language param will be sent)")
                    }
                    if let prompt = customPrompt {
                        print("   - Custom prompt: '\(prompt)'")
                    }
                    print("   - Model: \(selectedModel)")
                    
                    let result = try await openAIService.transcriptionAudio(
                        audioData: optimizedAudioData,
                        language: finalLanguage,
                        model: selectedModel,
                        customPrompt: customPrompt
                    )
                    
                    status = "TranCription completed!"
                    progress = 1.0
                    
                    // ã‚³ã‚¹ãƒˆè¿½è·¡ã¨ãƒ¬ãƒãƒ¼ãƒˆè¨˜éŒ²
                    if enableAudioOptimization && optimizedAudioData.count < audioData.count {
                        let originalCost = CreditManager.shared.calculateAPICost(duration: result.duration, model: selectedModel, isTranslation: false)
                        let optimizedCost = CreditManager.shared.calculateAPICost(duration: result.duration, model: selectedModel, isTranslation: false) * (Double(optimizedAudioData.count) / Double(audioData.count))
                        let savings = originalCost - optimizedCost
                        
                        CostReportManager.shared.recordUsage(
                            duration: result.duration,
                            model: selectedModel,
                            cost: optimizedCost,
                            isTranslation: false,
                            optimizationSavings: savings
                        )
                    } else {
                        let cost = CreditManager.shared.calculateAPICost(duration: result.duration, model: selectedModel, isTranslation: false)
                        CostReportManager.shared.recordUsage(
                            duration: result.duration,
                            model: selectedModel,
                            cost: cost,
                            isTranslation: false
                        )
                    }
                    
                    // ãƒˆãƒ¼ã‚¯ãƒ³è¨ˆç®—ã¨ä½¿ç”¨é‡è¿½è·¡
                    await TokenCalculationService.shared.calculateTokensForTranCription(
                        finalText: result.text,
                        duration: result.duration,
                        model: selectedModel,
                        isTranslation: false
                    )
                    
                    if let tokenStats = TokenCalculationService.shared.getLastResult() {
                        SubCriptionManager.shared.addTokenUsage(tokenStats.tokenCount)
                        
                        // ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ãƒã‚§ãƒƒã‚¯
                        if SubCriptionManager.shared.currentTokenUsage >= SubCriptionManager.shared.tokenLimit {
                            showingTokenLimitPrompt = true
                        }
                    }
                    
                    return result
                } catch {
                    // OpenAI API ã‚¨ãƒ©ãƒ¼ã®å ´åˆã€ã‚¨ãƒ©ãƒ¼ã‚’ãã®ã¾ã¾æŠ•ã’ã‚‹ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ãªã„ï¼‰
                    print("OpenAI API failed: \(error.localizedDescription)")
                    throw error
                }
                
            } else if isFireworksModel(selectedModel) && !isWhisperV3ServerlessModel(selectedModel) {
                // Fireworks Streamingãƒ¢ãƒ‡ãƒ«ï¼ˆfireworks-asr-large, fireworks-asr-v2ï¼‰ã¯Streamingå°‚ç”¨ã®ãŸã‚ã€ãƒ•ã‚¡ã‚¤ãƒ«è»¢å†™ã¯ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ãªã„
                status = "Fireworks streaming models are streaming-only..."
                progress = 0.1

                // WhisperKitã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                guard let whisperKit = whisperModelManager.whisperKit else {
                    throw TranCriptionError.whisperKitNotAvailable
                }

                status = "Using local model for file transcription..."
                progress = 0.2

                let result = try await performWhisperKitTranCription(
                    audioData: optimizedAudioData,
                    language: language,
                    whisperKit: whisperKit
                )

                status = "TranCription completed!"
                progress = 1.0

                return result
                
            } else if isWhisperV3ServerlessModel(selectedModel) {
                // Whisper V3 ã¨ Whisper V3 Turboã¯Serverless APIã‚’ä½¿ç”¨
                guard let serverlessService = fireworksServerlessService else {
                    print("âŒ Fireworks Serverless service not available - attempting to reload API key from Keychain")
                    loadAPIKeyFromKeychain()
                    
                    guard let retryServerlessService = fireworksServerlessService else {
                        print("âŒ Fireworks Serverless service still not available after reload attempt")
                        if hasFireworksAPIKeyInKeychain() {
                            throw TranCriptionError.openAIServiceNotAvailable
                        } else {
                            throw TranCriptionError.openAIAPIKeyNotSet
                        }
                    }
                    
                    status = "Using Fireworks Whisper V3 Turbo..."
                    progress = 0.3
                    
                    let result = try await retryServerlessService.transcribeAudio(
                        audioData: optimizedAudioData,
                        model: selectedModel,
                        language: language,
                        task: "transcribe"
                    )
                    
                    status = "TranCription completed!"
                    progress = 1.0
                    
                    return result
                }
                
                status = "Using Fireworks Whisper V3 Turbo..."
                progress = 0.3
                
                let result = try await serverlessService.transcribeAudio(
                    audioData: optimizedAudioData,
                    model: selectedModel,
                    language: language,
                    task: "transcribe"
                )
                
                status = "TranCription completed!"
                progress = 1.0
                
                return result
                
            } else {
                // WhisperKitãƒ¢ãƒ‡ãƒ«ã®å ´åˆ
                guard let whisperKit = whisperModelManager.whisperKit else {
                    throw TranCriptionError.whisperKitNotAvailable
                }
                
                status = "Using WhisperKit tranCription..."
                progress = 0.2
                
                let result = try await performWhisperKitTranCription(
                    audioData: optimizedAudioData,
                    language: language,
                    whisperKit: whisperKit
                )
                
                status = "TranCription completed!"
                progress = 1.0
                
                return result
            }
            
        } catch {
            print("âŒ TranscriptionServiceManager: Transcription failed: \(error)")
            if let tranCriptionError = error as? TranCriptionError {
                print("âŒ TranCriptionError details: \(tranCriptionError)")
                switch tranCriptionError {
                case .openAIServiceNotAvailable:
                    self.error = "OpenAI service is not available. Please check your API key in settings."
                case .openAIAPIKeyNotSet:
                    self.error = "OpenAI API key is not set. Please configure your API key in settings."
                case .whisperKitNotAvailable:
                    self.error = "Local model not loaded. Please load a model first."
                case .fileTooLarge:
                    self.error = "Audio file is too large. Please use a file smaller than 25MB."
                case .invalidAudioData:
                    self.error = "Invalid audio data format. Please check your audio file."
                case .subscriptionLimitExceeded:
                    self.error = "Monthly usage limit exceeded. Please upgrade your subscription or wait for the next billing cycle."
                case .insufficientCredits:
                    self.error = "Insufficient credits. Please purchase more credits to continue using API services."
                    // Free planã§ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆä¸è¶³ã®å ´åˆã¯ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆè³¼å…¥ç”»é¢ã‚’è¡¨ç¤º
                    let subscriptionManager = SubCriptionManager.shared
                    if subscriptionManager.subCriptionTier == .free {
                        self.showingCreditPurchaseSheet = true
                    }
                case .modelAccessDenied:
                    self.error = "This model is not available in your current subscription plan. Please upgrade to access cloud models."
                case .apiError(let statusCode, let message):
                    if statusCode == 403 {
                        self.error = "Model access denied. Please check your OpenAI API key permissions and ensure you have access to the selected OpenAI model."
                    } else {
                        self.error = "API Error \(statusCode): \(message)"
                    }
                default:
                    self.error = tranCriptionError.localizedDescription
                }
            } else {
                print("âŒ Unexpected error type: \(type(of: error))")
                self.error = "TranCription failed: \(error.localizedDescription)"
            }
            
            throw error
        }
    }
    
    func translateAudio(audioData: Data, targetLanguage: String? = nil) async throws -> TranCriptionResult {
        guard !isProcessing else {
            throw TranCriptionError.alreadyProcessing
        }
        
        isProcessing = true
        progress = 0.0
        status = "Preparing translation..."
        error = nil
        
        defer {
            isProcessing = false
            progress = 0.0
            status = ""
        }
        
        do {
            // ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ï¼ˆ25MBåˆ¶é™ï¼‰
            let maxFileSize = 25 * 1024 * 1024 // 25MB
            guard audioData.count <= maxFileSize else {
                throw TranCriptionError.fileTooLarge
            }
            
            // éŸ³å£°æœ€é©åŒ–ã‚’é©ç”¨ï¼ˆæœ‰åŠ¹åŒ–ã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
            var optimizedAudioData = audioData
            if enableAudioOptimization {
                status = "Optimizing audio..."
                progress = 0.1
                
                do {
                    // ç„¡éŸ³å‰Šé™¤ã‚’è©¦ã¿ã‚‹
                    let silenceRemoved = try await AudioOptimizer.removeSilence(from: audioData)
                    optimizedAudioData = silenceRemoved
                    
                    print("âœ… Audio optimization completed for translation")
                } catch {
                    // æœ€é©åŒ–ãŒå¤±æ•—ã—ã¦ã‚‚å…ƒã®ãƒ‡ãƒ¼ã‚¿ã§ç¶šè¡Œ
                    print("âš ï¸ Audio optimization failed, using original data: \(error)")
                }
            }
            
            // é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã«åŸºã¥ã„ã¦é©åˆ‡ãªã‚µãƒ¼ãƒ“ã‚¹ã‚’é¸æŠ
            guard let whisperModelManager = whisperModelManager else {
                throw TranCriptionError.whisperModelManagerNotAvailable
            }
            let selectedModel = whisperModelManager.selectedModel
            
            if isOpenAIModel(selectedModel) {
                // OpenAIãƒ¢ãƒ‡ãƒ«ã®å ´åˆï¼ˆtranslationsã¯whisper-1ã®ã¿ã‚µãƒãƒ¼ãƒˆï¼‰
                let translationModel = "whisper-1"
                
                guard let openAIService = openAIService else {
                    print("âŒ OpenAI service not available - attempting to reload API key from Keychain")
                    loadAPIKeyFromKeychain()
                    
                    guard let retryOpenAIService = openAIService else {
                        print("âŒ OpenAI service still not available after reload attempt")
                        if hasAPIKeyInKeychain() {
                            throw TranCriptionError.openAIServiceNotAvailable
                        } else {
                            throw TranCriptionError.openAIAPIKeyNotSet
                        }
                    }
                    
                    status = "Using OpenAI translation (retry)..."
                    progress = 0.2
                    
                    let result = try await retryOpenAIService.translateAudio(
                        audioData: optimizedAudioData,
                        model: translationModel,
                        targetLanguage: targetLanguage
                    )
                    
                    status = "Translation completed!"
                    progress = 1.0
                    
                    return result
                }
                
                status = "Using OpenAI translation..."
                progress = 0.2
                
                do {
                    let result = try await openAIService.translateAudio(
                        audioData: optimizedAudioData,
                        model: translationModel,
                        targetLanguage: targetLanguage
                    )
                    
                    status = "Translation completed!"
                    progress = 1.0
                    
                    // ã‚³ã‚¹ãƒˆè¿½è·¡ã¨ãƒ¬ãƒãƒ¼ãƒˆè¨˜éŒ²
                    if enableAudioOptimization && optimizedAudioData.count < audioData.count {
                        let originalCost = CreditManager.shared.calculateAPICost(duration: result.duration, model: translationModel, isTranslation: true)
                        let optimizedCost = CreditManager.shared.calculateAPICost(duration: result.duration, model: translationModel, isTranslation: true) * (Double(optimizedAudioData.count) / Double(audioData.count))
                        let savings = originalCost - optimizedCost
                        
                        CostReportManager.shared.recordUsage(
                            duration: result.duration,
                            model: translationModel,
                            cost: optimizedCost,
                            isTranslation: true,
                            optimizationSavings: savings
                        )
                    } else {
                        let cost = CreditManager.shared.calculateAPICost(duration: result.duration, model: translationModel, isTranslation: true)
                        CostReportManager.shared.recordUsage(
                            duration: result.duration,
                            model: translationModel,
                            cost: cost,
                            isTranslation: true
                        )
                    }
                    
                    return result
                } catch {
                    print("OpenAI Translation API failed: \(error.localizedDescription)")
                    throw error
                }
                
            } else if isWhisperV3ServerlessModel(selectedModel) {
                // Whisper V3 ã¨ Whisper V3 Turboã¯Serverless APIã‚’ä½¿ç”¨
                guard let serverlessService = fireworksServerlessService else {
                    print("âŒ Fireworks Serverless service not available - attempting to reload API key from Keychain")
                    loadAPIKeyFromKeychain()
                    
                    guard let retryServerlessService = fireworksServerlessService else {
                        print("âŒ Fireworks Serverless service still not available after reload attempt")
                        if hasFireworksAPIKeyInKeychain() {
                            throw TranCriptionError.openAIServiceNotAvailable
                        } else {
                            throw TranCriptionError.openAIAPIKeyNotSet
                        }
                    }
                    
                    status = "Using Fireworks Whisper V3 Turbo for translation..."
                    progress = 0.3
                    
                    let result = try await retryServerlessService.transcribeAudio(
                        audioData: optimizedAudioData,
                        model: selectedModel,
                        language: nil, // è‡ªå‹•æ¤œå‡º
                        task: "translate"
                    )
                    
                    status = "Translation completed!"
                    progress = 1.0
                    
                    return result
                }
                
                status = "Using Fireworks Whisper V3 Turbo for translation..."
                progress = 0.3
                
                let result = try await serverlessService.transcribeAudio(
                    audioData: optimizedAudioData,
                    model: selectedModel,
                    language: nil, // è‡ªå‹•æ¤œå‡º
                    task: "translate"
                )
                
                status = "Translation completed!"
                progress = 1.0
                
                return result
                
            } else {
                // WhisperKitãƒ¢ãƒ‡ãƒ«ã®å ´åˆ
                guard let whisperKit = whisperModelManager.whisperKit else {
                    throw TranCriptionError.whisperKitNotAvailable
                }
                
                status = "Using WhisperKit translation..."
                progress = 0.2
                
                // WhisperKitã®ç¿»è¨³ã‚¿ã‚¹ã‚¯ã‚’ä½¿ç”¨
                let result = try await performWhisperKitTranslation(
                    audioData: optimizedAudioData,
                    whisperKit: whisperKit
                )
                
                // targetLanguageãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã€ã•ã‚‰ã«GPT-4o-miniã§ç¿»è¨³
                if let targetLanguage = targetLanguage, targetLanguage != "en" {
                    guard let textTranslationService = textTranslationService else {
                        print("âš ï¸ Text translation service not available - returning English result")
                        return result
                    }
                    
                    status = "Translating to \(targetLanguage)..."
                    progress = 0.6
                    
                    let translatedText = try await textTranslationService.translateText(text: result.text, targetLanguage: targetLanguage)
                    
                    return TranCriptionResult(
                        text: translatedText,
                        segments: [],
                        language: targetLanguage,
                        duration: result.duration
                    )
                }
                
                status = "Translation completed!"
                progress = 1.0
                
                return result
            }
            
        } catch {
            self.error = error.localizedDescription
            print("Translation failed: \(error.localizedDescription)")
            
            if let tranCriptionError = error as? TranCriptionError {
                switch tranCriptionError {
                case .openAIServiceNotAvailable:
                    self.error = "OpenAI service is not available. Please check your API key in settings."
                case .openAIAPIKeyNotSet:
                    self.error = "OpenAI API key is not set. Please configure your API key in settings."
                case .whisperKitNotAvailable:
                    self.error = "Local model not loaded. Please load a model first."
                case .fileTooLarge:
                    self.error = "Audio file is too large. Please use a file smaller than 25MB."
                case .insufficientCredits:
                    self.error = "Insufficient credits. Please purchase more credits to continue using API services."
                    // Free planã§ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆä¸è¶³ã®å ´åˆã¯ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆè³¼å…¥ç”»é¢ã‚’è¡¨ç¤º
                    let subscriptionManager = SubCriptionManager.shared
                    if subscriptionManager.subCriptionTier == .free {
                        self.showingCreditPurchaseSheet = true
                    }
                case .apiError(let statusCode, let message):
                    self.error = "API Error \(statusCode): \(message)"
                default:
                    self.error = tranCriptionError.localizedDescription
                }
            } else {
                self.error = "Translation failed: \(error.localizedDescription)"
            }
            
            throw error
        }
    }
    
    // MARK: - Private Methods
    
    private func isOpenAIModel(_ modelId: String) -> Bool {
        return modelId == "whisper-1" || modelId == "gpt-4o-transcribe" || modelId == "gpt-4o-mini-transcribe"
    }
    
    private func isParakeetModel(_ modelId: String) -> Bool {
        return modelId == "parakeet-tdt-0.6b-v3" || modelId == "parakeet-tdt-0.6b-v2"
    }
    
    private func isFireworksModel(_ modelId: String) -> Bool {
        return modelId == "fireworks-asr-large" ||
               modelId == "fireworks-asr-v2" ||
               modelId == "whisper-v3" ||
               modelId == "whisper-v3-turbo"
    }
    
    private func isWhisperV3Model(_ modelId: String) -> Bool {
        return modelId == "whisper-v3" ||
               modelId == "whisper-v3-turbo"
    }
    
    private func isWhisperV3ServerlessModel(_ modelId: String) -> Bool {
        return modelId == "whisper-v3" ||
               modelId == "whisper-v3-turbo"
    }
    
    private func performWhisperKitTranCription(
        audioData: Data,
        language: String?,
        whisperKit: WhisperKit
    ) async throws -> TranCriptionResult {
        
        status = "Processing with WhisperKit..."
        progress = 0.5
        
        // Convert Data to audio samples
        let audioSamples = try await convertAudioDataToSamples(audioData)
        
        guard !audioSamples.isEmpty else {
            throw TranCriptionError.invalidAudioData
        }
        
        // è¨€èªãŒ"auto"ã®å ´åˆã¯nilã«ã—ã¦è‡ªå‹•æ¤œå‡ºã‚’æœ‰åŠ¹åŒ–
        let finalLanguage = (language == "auto") ? nil : language
        
        // WhisperKitã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ã‚’è»¢å†™ï¼ˆå®Œå…¨ãªè»¢å†™ã®ãŸã‚Early Stoppingã‚’ç„¡åŠ¹åŒ–ï¼‰
        let results = try await whisperKit.transcribe(
            audioArray: audioSamples,
            decodeOptions: DecodingOptions(
                task: .transcribe,
                language: finalLanguage,
                temperatureFallbackCount: 5,     // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§å®Œå…¨ãªè»¢å†™ã‚’ç¢ºä¿
                sampleLength: 224,               // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§å®Œå…¨ãªè»¢å†™ã‚’ç¢ºä¿
                compressionRatioThreshold: 2.4,  // ã‚ˆã‚Šç·©ã„é–¾å€¤ã§å®Œå…¨ãªè»¢å†™ã‚’ç¢ºä¿
                logProbThreshold: -1.0           // ã‚ˆã‚Šç·©ã„é–¾å€¤ã§å®Œå…¨ãªè»¢å†™ã‚’ç¢ºä¿
            )
        )
        
        status = "Parsing response..."
        progress = 0.8
        
        // WhisperKitã®çµæœã‚’TranCriptionResultã«å¤‰æ›
        guard let result = results.first else {
            throw TranCriptionError.invalidResponse
        }
        
        let segments = result.segments.map { segment in
            TranCriptionSegment(
                start: Double(segment.start),
                end: Double(segment.end),
                text: filterMusicAndSoundEffects(segment.text)
            )
        }
        
        return TranCriptionResult(
            text: filterMusicAndSoundEffects(result.text),
            segments: segments,
            language: result.language,
            duration: segments.last?.end ?? 0.0
        )
    }
    
    // éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚µãƒ³ãƒ—ãƒ«é…åˆ—ã«å¤‰æ›
    private func convertAudioDataToSamples(_ audioData: Data) async throws -> [Float] {
        // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
        let tempURL = FileManager.default.temporaryDirectory.appendingPathComponent("temp_audio_\(UUID().uuidString).m4a")
        try audioData.write(to: tempURL)
        
        defer {
            try? FileManager.default.removeItem(at: tempURL)
        }
        
        // AVAudioFileã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        let audioFile = try AVAudioFile(forReading: tempURL)
        let audioFormat = audioFile.processingFormat
        let audioFrameCount = UInt32(audioFile.length)
        
        guard let audioBuffer = AVAudioPCMBuffer(pcmFormat: audioFormat, frameCapacity: audioFrameCount) else {
            throw TranCriptionError.invalidAudioData
        }
        
        try audioFile.read(into: audioBuffer)
        
        // PCMãƒãƒƒãƒ•ã‚¡ã‚’Floaté…åˆ—ã«å¤‰æ›
        guard let channelData = audioBuffer.floatChannelData else {
            throw TranCriptionError.invalidAudioData
        }
        
        let channelDataValue = channelData.pointee
        let channelDataValueArray = stride(from: 0, to: Int(audioBuffer.frameLength), by: audioBuffer.stride).map { channelDataValue[$0] }
        
        // å¿…è¦ã«å¿œã˜ã¦ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° (WhisperKitã¯16kHzã‚’æƒ³å®š)
        let targetSampleRate = 16000.0
        if audioFormat.sampleRate != targetSampleRate {
            return try await resampleAudio(channelDataValueArray, from: audioFormat.sampleRate, to: targetSampleRate)
        }
        
        return channelDataValueArray
    }
    
    // éŸ³å£°ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    private func resampleAudio(_ samples: [Float], from sourceSampleRate: Double, to targetSampleRate: Double) async throws -> [Float] {
        let ratio = targetSampleRate / sourceSampleRate
        let outputLength = Int(Double(samples.count) * ratio)
        var resampled: [Float] = []
        resampled.reserveCapacity(outputLength)
        
        for i in 0..<outputLength {
            let sourceIndex = Double(i) / ratio
            let lowerIndex = Int(sourceIndex)
            let upperIndex = min(lowerIndex + 1, samples.count - 1)
            let fraction = Float(sourceIndex - Double(lowerIndex))
            
            let interpolated = samples[lowerIndex] * (1.0 - fraction) + samples[upperIndex] * fraction
            resampled.append(interpolated)
        }
        
        return resampled
    }
    
    // MARK: - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ©Ÿèƒ½
    
    // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŒ²éŸ³é–‹å§‹
    func startRealtimeRecording(language: String? = nil, delayInterval: Float = 1.0) async throws {
        guard !isRecording else {
            throw TranCriptionError.alreadyProcessing
        }
        
        // é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã«åŸºã¥ã„ã¦é©åˆ‡ãªã‚µãƒ¼ãƒ“ã‚¹ã‚’é¸æŠ
        guard let whisperModelManager = whisperModelManager else {
            throw TranCriptionError.whisperModelManagerNotAvailable
        }
        let selectedModel = whisperModelManager.selectedModel
        
        // ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã‹ã©ã†ã‹ã‚’åˆ¤å®š
        let isStreamingModel = selectedModel == "whisper-1" || 
                               selectedModel == "gpt-4o-transcribe" || 
                               selectedModel == "gpt-4o-mini-transcribe"
        
            let isFireworksStreamingModel = isFireworksModel(selectedModel)
        
        if isStreamingModel {
            // OpenAI Streamingã‚µãƒ¼ãƒ“ã‚¹ã‚’ç›´æ¥ä½¿ç”¨ï¼ˆRealtime APIã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’å‰Šé™¤ï¼‰
            guard let streamingService = openAIStreamingService else {
                print("âŒ OpenAI Streaming service not available - attempting to reload API key from Keychain")
                loadAPIKeyFromKeychain()
                
                guard let retryStreamingService = openAIStreamingService else {
                    print("âŒ OpenAI Streaming service still not available after reload attempt")
                    if hasAPIKeyInKeychain() {
                        throw TranCriptionError.openAIServiceNotAvailable
                    } else {
                        throw TranCriptionError.openAIAPIKeyNotSet
                    }
                }
                
                try await retryStreamingService.startStreamingTranscription(model: selectedModel, language: language)
                isRecording = true
                isTranscribing = true
                
                // OpenAI Streamingã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç›£è¦–
                observeOpenAIStreamingText()
                return
            }
            
            try await streamingService.startStreamingTranscription(model: selectedModel, language: language)
            isRecording = true
            isTranscribing = true
            
            // OpenAI Streamingã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç›£è¦–
            observeOpenAIStreamingText()
            
        } else if isFireworksStreamingModel {
            // Fireworks Streamingã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ç”¨
            guard let fireworksService = fireworksStreamingService else {
                print("âŒ Fireworks Streaming service not available - attempting to reload API key from Keychain")
                loadAPIKeyFromKeychain()
                
                guard let retryFireworksService = fireworksStreamingService else {
                    print("âŒ Fireworks Streaming service still not available after reload attempt")
                    if hasFireworksAPIKeyInKeychain() {
                        throw TranCriptionError.openAIServiceNotAvailable
                    } else {
                        throw TranCriptionError.openAIAPIKeyNotSet
                    }
                }
                
                try await retryFireworksService.startStreamingTranscription(model: selectedModel, language: language)
                isRecording = true
                isTranscribing = true
                
                // Fireworks Streamingã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç›£è¦–
                observeFireworksStreamingText()
                return
            }
            
            try await fireworksService.startStreamingTranscription(model: selectedModel, language: language)
            isRecording = true
            isTranscribing = true
            
            // Fireworks Streamingã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç›£è¦–
            observeFireworksStreamingText()
            
        } else {
            // WhisperKitã‚’ä½¿ç”¨
            guard let whisperKit = whisperModelManager.whisperKit else {
                throw TranCriptionError.whisperKitNotAvailable
            }
            
            do {
                try whisperKit.audioProcessor.startRecordingLive { [weak self] _ in
                    Task { @MainActor [weak self] in
                        guard let self = self else { return }
                        self.bufferSeconds = Double(whisperKit.audioProcessor.audioSamples.count) / Double(WhisperKit.sampleRate)
                    }
                }
                
                isRecording = true
                isTranscribing = true
                realtimeText = "Recording started..."
                lastBufferSize = 0
                
                // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ«ãƒ¼ãƒ—é–‹å§‹
                startRealtimeLoop(language: language, delayInterval: delayInterval)
                
            } catch {
                isRecording = false
                isTranscribing = false
                throw error
            }
        }
    }
    
    // OpenAIRealtimeã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç›£è¦–
    private func observeOpenAIRealtimeText() {
        tranCriptionTask = Task { @MainActor in
            while isRecording && isTranscribing {
                if let realtimeService = openAIRealtimeService {
                    self.realtimeText = realtimeService.realtimeText
                    if let error = realtimeService.error {
                        self.error = error
                    }
                }
                try? await Task.sleep(nanoseconds: 100_000_000) // 100mså¾…æ©Ÿ
            }
        }
    }
    
    // OpenAI Streamingã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç›£è¦–
    private func observeOpenAIStreamingText() {
        tranCriptionTask = Task { @MainActor in
            while isRecording && isTranscribing {
                if let streamingService = openAIStreamingService {
                    self.realtimeText = streamingService.streamingText
                    if let error = streamingService.error {
                        self.error = error
                    }
                }
                try? await Task.sleep(nanoseconds: 100_000_000) // 100mså¾…æ©Ÿ
            }
        }
    }
    
    // Fireworks Streamingã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç›£è¦–
    private func observeFireworksStreamingText() {
        tranCriptionTask = Task { @MainActor in
            while isRecording && isTranscribing {
                if let fireworksService = fireworksStreamingService {
                    self.realtimeText = fireworksService.streamingText
                    if let error = fireworksService.error {
                        self.error = error
                    }
                }
                try? await Task.sleep(nanoseconds: 100_000_000) // 100mså¾…æ©Ÿ
            }
        }
    }
    
    // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŒ²éŸ³åœæ­¢
    func stopRealtimeRecording() {
        isTranscribing = false
        tranCriptionTask?.cancel()
        
        // OpenAI Streamingã‚µãƒ¼ãƒ“ã‚¹ã®åœæ­¢ï¼ˆç›´æ¥ä½¿ç”¨ï¼‰
        if let streamingService = openAIStreamingService, streamingService.isRecording {
            Task {
                await streamingService.stopStreamingTranscription()
            }
        }
        
        // Fireworks Streamingã‚µãƒ¼ãƒ“ã‚¹ã®åœæ­¢
        if let fireworksService = fireworksStreamingService, fireworksService.isRecording {
            Task {
                await fireworksService.stopStreamingTranscription()
            }
        }
        
        // OpenAI Realtimeã‚µãƒ¼ãƒ“ã‚¹ã®åœæ­¢ï¼ˆãƒ¬ã‚¬ã‚·ãƒ¼ã€ä½¿ç”¨ã—ãªã„ï¼‰
        if let realtimeService = openAIRealtimeService, realtimeService.isRecording {
            Task {
                await realtimeService.stopRealtimeTranscription()
            }
        }
        
        // WhisperKitã®åœæ­¢
        if let whisperKit = whisperModelManager?.whisperKit {
            whisperKit.audioProcessor.stopRecording()
        }
        
        isRecording = false
    }
    
    // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ«ãƒ¼ãƒ—
    private func startRealtimeLoop(language: String?, delayInterval: Float) {
        tranCriptionTask = Task {
            while isRecording && isTranscribing {
                do {
                    try await tranCriptionCurrentBuffer(language: language, delayInterval: delayInterval)
                } catch {
                    await MainActor.run {
                        self.error = error.localizedDescription
                    }
                    break
                }
            }
        }
    }
    
    // ç¾åœ¨ã®ãƒãƒƒãƒ•ã‚¡ã‚’ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒ©ã‚¤ãƒ–
    private func tranCriptionCurrentBuffer(language: String?, delayInterval: Float) async throws {
        guard let whisperKit = whisperModelManager?.whisperKit else {
            throw TranCriptionError.whisperKitNotAvailable
        }
        
        // ç¾åœ¨ã®ãƒãƒƒãƒ•ã‚¡ã‚’å–å¾—
        let currentBuffer = whisperKit.audioProcessor.audioSamples
        
        // æ¬¡ã®ãƒãƒƒãƒ•ã‚¡ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ã‚µã‚¤ã‚ºã¨æ™‚é–“ã‚’è¨ˆç®—
        let nextBufferSize = currentBuffer.count - lastBufferSize
        let nextBufferSeconds = Float(nextBufferSize) / Float(WhisperKit.sampleRate)
        
        // delayIntervalç§’ä»¥ä¸Šã®éŸ³å£°ãŒã‚ã‚‹å ´åˆã®ã¿ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒ©ã‚¤ãƒ–
        guard nextBufferSeconds > delayInterval else {
            try await Task.sleep(nanoseconds: 50_000_000) // 50mså¾…æ©Ÿ
            return
        }
        
        // ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºã‚’æ›´æ–°
        lastBufferSize = currentBuffer.count
        
        // è¨€èªãŒ"auto"ã®å ´åˆã¯nilã«ã—ã¦è‡ªå‹•æ¤œå‡ºã‚’æœ‰åŠ¹åŒ–
        let finalLanguage = (language == "auto") ? nil : language
        
        // ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒ©ã‚¤ãƒ–å®Ÿè¡Œï¼ˆå®Œå…¨ãªè»¢å†™ã®ãŸã‚Early Stoppingã‚’ç„¡åŠ¹åŒ–ï¼‰
        let results = try await whisperKit.transcribe(
            audioArray: Array(currentBuffer),
            decodeOptions: DecodingOptions(
                task: .transcribe,
                language: finalLanguage,
                temperatureFallbackCount: 3,     // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ã‚‚é©åˆ‡ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å›æ•°
                sampleLength: 224,               // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§å®Œå…¨ãªè»¢å†™ã‚’ç¢ºä¿
                skipSpecialTokens: true,
                compressionRatioThreshold: 2.4,  // ã‚ˆã‚Šç·©ã„é–¾å€¤ã§å®Œå…¨ãªè»¢å†™ã‚’ç¢ºä¿
                logProbThreshold: -1.0           // ã‚ˆã‚Šç·©ã„é–¾å€¤ã§å®Œå…¨ãªè»¢å†™ã‚’ç¢ºä¿
            )
        )
        
        // çµæœã‚’æ›´æ–°
        if let result = results.first {
            await MainActor.run {
                self.realtimeText = filterMusicAndSoundEffects(result.text)
            }
        }
    }
    
    private func performWhisperKitTranslation(
        audioData: Data,
        whisperKit: WhisperKit
    ) async throws -> TranCriptionResult {
        
        status = "Processing translation with WhisperKit..."
        progress = 0.5
        
        // Convert Data to audio samples
        let audioSamples = try await convertAudioDataToSamples(audioData)
        
        guard !audioSamples.isEmpty else {
            throw TranCriptionError.invalidAudioData
        }
        
        // WhisperKitã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ã‚’ç¿»è¨³ï¼ˆå¸¸ã«è‹±èªã«ç¿»è¨³ã€å®Œå…¨ãªè»¢å†™ã®ãŸã‚Early Stoppingã‚’ç„¡åŠ¹åŒ–ï¼‰
        let results = try await whisperKit.transcribe(
            audioArray: audioSamples,
            decodeOptions: DecodingOptions(
                task: .translate,
                language: nil,  // è‡ªå‹•æ¤œå‡º
                temperatureFallbackCount: 5,     // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§å®Œå…¨ãªè»¢å†™ã‚’ç¢ºä¿
                sampleLength: 224,               // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§å®Œå…¨ãªè»¢å†™ã‚’ç¢ºä¿
                compressionRatioThreshold: 2.4,  // ã‚ˆã‚Šç·©ã„é–¾å€¤ã§å®Œå…¨ãªè»¢å†™ã‚’ç¢ºä¿
                logProbThreshold: -1.0           // ã‚ˆã‚Šç·©ã„é–¾å€¤ã§å®Œå…¨ãªè»¢å†™ã‚’ç¢ºä¿
            )
        )
        
        status = "Parsing response..."
        progress = 0.8
        
        // WhisperKitã®çµæœã‚’TranCriptionResultã«å¤‰æ›
        guard let result = results.first else {
            throw TranCriptionError.invalidResponse
        }
        
        let segments = result.segments.map { segment in
            TranCriptionSegment(
                start: Double(segment.start),
                end: Double(segment.end),
                text: filterMusicAndSoundEffects(segment.text)
            )
        }
        
        return TranCriptionResult(
            text: filterMusicAndSoundEffects(result.text),
            segments: segments,
            language: "en",  // ç¿»è¨³ã¯å¸¸ã«è‹±èª
            duration: segments.last?.end ?? 0.0
        )
    }
    
    
    // MARK: - Text Filtering
    
    /// éŸ³æ¥½ã‚„éŸ³éŸ¿åŠ¹æœã®è¡¨è¨˜ã‚’é™¤å»ã™ã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é–¢æ•°
    private func filterMusicAndSoundEffects(_ text: String) -> String {
        var filteredText = text
        
        // []ã§å›²ã¾ã‚ŒãŸéŸ³æ¥½è¡¨è¨˜ã‚’é™¤å»ï¼ˆå¤§æ–‡å­—å°æ–‡å­—ã‚’åŒºåˆ¥ã—ãªã„ï¼‰
        filteredText = filteredText.replacingOccurrences(
            of: "\\[[^\\]]*\\]",
            with: "",
            options: [.regularExpression, .caseInsensitive]
        )
        
        // ()ã§å›²ã¾ã‚ŒãŸéŸ³æ¥½è¡¨è¨˜ã‚’é™¤å»ï¼ˆå¤§æ–‡å­—å°æ–‡å­—ã‚’åŒºåˆ¥ã—ãªã„ï¼‰
        filteredText = filteredText.replacingOccurrences(
            of: "\\([^)]*\\)",
            with: "",
            options: [.regularExpression, .caseInsensitive]
        )
        
        // ç‰¹å®šã®éŸ³æ¥½é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ç„¡éŸ³è¡¨è¨˜ã‚’é™¤å»ï¼ˆå…¨ã¦å¤§æ–‡å­—ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚‚è¿½åŠ ï¼‰
        let musicKeywords = [
            "music playing", "electronic music", "upbeat music", "background music",
            "instrumental music", "classical music", "jazz music", "rock music",
            "pop music", "dance music", "ambient music", "soft music",
            "blank audio", "blank_audio", "BLANK_AUDIO", "silence", "quiet", "no sound",
            "MUSIC PLAYING", "ELECTRONIC MUSIC", "UPBEAT MUSIC", "BACKGROUND MUSIC",
            "INSTRUMENTAL MUSIC", "CLASSICAL MUSIC", "JAZZ MUSIC", "ROCK MUSIC",
            "POP MUSIC", "DANCE MUSIC", "AMBIENT MUSIC", "SOFT MUSIC",
            "BLANK AUDIO", "BLANK_AUDIO", "SILENCE", "QUIET", "NO SOUND"
        ]
        
        for keyword in musicKeywords {
            // å¤§æ–‡å­—å°æ–‡å­—ã‚’åŒºåˆ¥ã›ãšã«é™¤å»
            filteredText = filteredText.replacingOccurrences(
                of: keyword,
                with: "",
                options: .caseInsensitive
            )
        }
        
        // è¤‡æ•°ã®ã‚¹ãƒšãƒ¼ã‚¹ã‚’å˜ä¸€ã®ã‚¹ãƒšãƒ¼ã‚¹ã«æ­£è¦åŒ–
        filteredText = filteredText.replacingOccurrences(
            of: "\\s+",
            with: " ",
            options: .regularExpression
        )
        
        // å…ˆé ­ã¨æœ«å°¾ã®ç©ºç™½ã‚’é™¤å»
        return filteredText.trimmingCharacters(in: .whitespacesAndNewlines)
    }
}
