//  For licensing see accompanying LICENSE.md file.
//  Copyright Â© 2025 Cription. All rights reserved.

import Foundation
import SwiftUI
import WhisperKit

// MARK: - OpenAI TranCription Service

@MainActor
class OpenAITranCriptionService: ObservableObject {
    @Published var isProcessing = false
    @Published var progress: Double = 0.0
    @Published var status: String = ""
    @Published var error: String?
    
    private let apiKey: String
    private let baseURL = "https://api.openai.com/v1/audio/transcriptions"
    private let subscriptionManager = SubCriptionManager()
    
    init(apiKey: String) {
        self.apiKey = apiKey
    }
    
    // MARK: - Public Methods
    
    func transcriptionAudio(audioData: Data, language: String? = nil, model: String = "whisper-1", customPrompt: String? = nil) async throws -> TranCriptionResult {
        guard !isProcessing else {
            throw TranCriptionError.alreadyProcessing
        }
        
        // ã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³åˆ¶é™ãƒã‚§ãƒƒã‚¯
        guard subscriptionManager.canUseOpenAITranCription() else {
            throw TranCriptionError.subscriptionLimitExceeded
        }
        
        // ãƒ¢ãƒ‡ãƒ«ã‚¢ã‚¯ã‚»ã‚¹åˆ¶é™ãƒã‚§ãƒƒã‚¯
        guard subscriptionManager.canUseCloudModel(model) else {
            // Free planã§ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆä¸è¶³ã®å ´åˆã¯insufficientCreditsã‚¨ãƒ©ãƒ¼ã‚’æŠ•ã’ã‚‹
            if subscriptionManager.subCriptionTier == .free {
                throw TranCriptionError.insufficientCredits
            } else {
                throw TranCriptionError.modelAccessDenied
            }
        }
        
        isProcessing = true
        progress = 0.0
        status = "Preparing tranCription..."
        error = nil
        
        defer {
            isProcessing = false
            progress = 0.0
            status = ""
        }
        
        do {
            // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬æ¤œè¨¼
            guard !audioData.isEmpty else {
                print("âŒ Audio data is empty")
                throw TranCriptionError.invalidAudioData
            }
            
            // ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ï¼ˆ25MBåˆ¶é™ï¼‰
            let maxFileSize = 25 * 1024 * 1024 // 25MB
            guard audioData.count <= maxFileSize else {
                print("âŒ Audio file too large: \(audioData.count) bytes (max: \(maxFileSize))")
                throw TranCriptionError.fileTooLarge
            }
            
            // æœ€å°ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ï¼ˆç©ºã§ãªã„ã“ã¨ã‚’ç¢ºèªï¼‰
            let minFileSize = 1024 // 1KB
            guard audioData.count >= minFileSize else {
                print("âŒ Audio file too small: \(audioData.count) bytes (min: \(minFileSize))")
                throw TranCriptionError.invalidAudioData
            }
            
            print("âœ… Audio data validation passed: \(audioData.count) bytes")
            
            status = "Uploading audio to OpenAI..."
            progress = 0.2
            
            // è¨€èªãŒ"auto"ã®å ´åˆã¯nilã«ã—ã¦è‡ªå‹•æ¤œå‡ºã‚’æœ‰åŠ¹åŒ–
            let finalLanguage = (language == "auto" || language == nil) ? nil : language
            
            let result = try await performTranCription(audioData: audioData, language: finalLanguage, model: model, customPrompt: customPrompt)
            
            // ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã¾ãŸã¯ä½¿ç”¨é‡ã‚’æ¶ˆè²»
            let success = subscriptionManager.consumeAPICredits(
                duration: result.duration,
                model: model,
                isTranslation: false
            )
            
            guard success else {
                throw TranCriptionError.insufficientCredits
            }
            
            status = "TranCription completed!"
            progress = 1.0
            
            return result
            
        } catch {
            print("âŒ OpenAI transcription failed: \(error)")
            if let tranCriptionError = error as? TranCriptionError {
                print("âŒ TranCriptionError details: \(tranCriptionError)")
                self.error = tranCriptionError.localizedDescription
            } else {
                print("âŒ Unexpected error type: \(type(of: error))")
                self.error = error.localizedDescription
            }
            throw error
        }
    }
    
    func translateAudio(audioData: Data, model: String = "whisper-1", targetLanguage: String? = nil) async throws -> TranCriptionResult {
        guard !isProcessing else {
            throw TranCriptionError.alreadyProcessing
        }
        
        // ã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³åˆ¶é™ãƒã‚§ãƒƒã‚¯
        guard subscriptionManager.canUseOpenAITranCription() else {
            throw TranCriptionError.subscriptionLimitExceeded
        }
        
        // ãƒ¢ãƒ‡ãƒ«ã‚¢ã‚¯ã‚»ã‚¹åˆ¶é™ãƒã‚§ãƒƒã‚¯
        guard subscriptionManager.canUseCloudModel(model) else {
            // Free planã§ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆä¸è¶³ã®å ´åˆã¯insufficientCreditsã‚¨ãƒ©ãƒ¼ã‚’æŠ•ã’ã‚‹
            if subscriptionManager.subCriptionTier == .free {
                throw TranCriptionError.insufficientCredits
            } else {
                throw TranCriptionError.modelAccessDenied
            }
        }
        
        isProcessing = true
        progress = 0.0
        status = "Preparing translation..."
        error = nil
        
        defer {
            isProcessing = false
            progress = 0.0
            status = ""
        }
        
        do {
            // ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ï¼ˆ25MBåˆ¶é™ï¼‰
            let maxFileSize = 25 * 1024 * 1024 // 25MB
            guard audioData.count <= maxFileSize else {
                throw TranCriptionError.fileTooLarge
            }
            
            status = "Uploading audio to OpenAI..."
            progress = 0.2
            
            let result = try await performTranslation(audioData: audioData, model: model)
            
            // ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã¾ãŸã¯ä½¿ç”¨é‡ã‚’æ¶ˆè²»
            let success = subscriptionManager.consumeAPICredits(
                duration: result.duration,
                model: model,
                isTranslation: true
            )
            
            guard success else {
                throw TranCriptionError.insufficientCredits
            }
            
            // targetLanguageãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã€ã•ã‚‰ã«GPT-4o-miniã§ç¿»è¨³
            if let targetLanguage = targetLanguage, targetLanguage != "en" {
                status = "Translating to \(targetLanguage)..."
                progress = 0.6
                
                let textTranslationService = OpenAITextTranslationService(apiKey: apiKey)
                let translatedText = try await textTranslationService.translateText(text: result.text, targetLanguage: targetLanguage)
                
                return TranCriptionResult(
                    text: translatedText,
                    segments: [],
                    language: targetLanguage,
                    duration: result.duration
                )
            }
            
            status = "Translation completed!"
            progress = 1.0
            
            return result
            
        } catch {
            print("âŒ OpenAI translation failed: \(error)")
            if let tranCriptionError = error as? TranCriptionError {
                print("âŒ TranCriptionError details: \(tranCriptionError)")
                self.error = tranCriptionError.localizedDescription
            } else {
                print("âŒ Unexpected error type: \(type(of: error))")
                self.error = error.localizedDescription
            }
            throw error
        }
    }
    
    // MARK: - Private Methods
    
    private func performTranCription(audioData: Data, language: String?, model: String, customPrompt: String? = nil) async throws -> TranCriptionResult {
        print("ğŸ”µ OpenAI API call starting - model: \(model), audioData size: \(audioData.count) bytes")
        if let lang = language {
            print("ğŸ”µ Language parameter: '\(lang)' (explicit language specified)")
        } else {
            print("ğŸ”µ Language parameter: nil (auto-detect mode)")
        }
        if let prompt = customPrompt {
            print("ğŸ”µ Custom prompt: '\(prompt)'")
        }
        
        guard let url = URL(string: baseURL) else {
            print("âŒ Invalid URL: \(baseURL)")
            throw TranCriptionError.invalidURL
        }
        
        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.setValue("Bearer \(apiKey)", forHTTPHeaderField: "Authorization")
        print("ğŸ”µ API request prepared - URL: \(baseURL)")
        
        // ãƒãƒ«ãƒãƒ‘ãƒ¼ãƒˆãƒ•ã‚©ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆï¼ˆcheck-list.mdã®å®Ÿè£…ã«åŸºã¥ãï¼‰
        let boundary = "Boundary-\(UUID().uuidString)"
        request.setValue("multipart/form-data; boundary=\(boundary)", forHTTPHeaderField: "Content-Type")
        
        var body = Data()
        
        // ãƒ¢ãƒ‡ãƒ«æŒ‡å®šï¼ˆæœ€åˆã«è¿½åŠ ï¼‰
        body.appendString("--\(boundary)\r\n")
        body.appendString("Content-Disposition: form-data; name=\"model\"\r\n\r\n")
        body.appendString("\(model)\r\n")
        
        // è¨€èªæŒ‡å®šï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if let language = language {
            print("ğŸ”µ Adding language parameter to request: \(language)")
            body.appendString("--\(boundary)\r\n")
            body.appendString("Content-Disposition: form-data; name=\"language\"\r\n\r\n")
            body.appendString("\(language)\r\n")
        } else {
            print("âœ… AUTO-DETECT MODE: No language parameter specified - OpenAI will detect the language automatically")
            print("   - This allows OpenAI to correctly identify the audio language (e.g., Japanese, English, etc.)")
        }
        
        // promptãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®šï¼ˆã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå„ªå…ˆï¼‰
        if let customPrompt = customPrompt, !customPrompt.isEmpty {
            // ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨
            print("ğŸ”µ Adding custom user prompt: \(customPrompt)")
            body.appendString("--\(boundary)\r\n")
            body.appendString("Content-Disposition: form-data; name=\"prompt\"\r\n\r\n")
            body.appendString("\(customPrompt)\r\n")
        } else if let language = language {
            // ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒãªã„å ´åˆã¯è¨€èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨
            let languagePrompt = getLanguagePrompt(for: language)
            print("ğŸ”µ Adding language prompt to guide output language: \(languagePrompt)")
            body.appendString("--\(boundary)\r\n")
            body.appendString("Content-Disposition: form-data; name=\"prompt\"\r\n\r\n")
            body.appendString("\(languagePrompt)\r\n")
        }
        
        // ãƒ•ã‚¡ã‚¤ãƒ«éƒ¨åˆ†ï¼ˆé©åˆ‡ãªMIMEã‚¿ã‚¤ãƒ—ã¨ãƒ•ã‚¡ã‚¤ãƒ«åï¼‰
        let (filename, mimeType) = detectAudioFormat(from: audioData)
        body.appendString("--\(boundary)\r\n")
        body.appendString("Content-Disposition: form-data; name=\"file\"; filename=\"\(filename)\"\r\n")
        body.appendString("Content-Type: \(mimeType)\r\n\r\n")
        body.append(audioData)
        body.appendString("\r\n")
        
        // ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ã¨ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—è¨­å®šï¼ˆãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚Šç•°ãªã‚‹ï¼‰
        if model.contains("gpt-4o") {
            // gpt-4oç³»ãƒ¢ãƒ‡ãƒ«ã¯jsonã®ã¿ã‚µãƒãƒ¼ãƒˆ
            print("ğŸ”µ Using json response format for GPT-4o model")
            body.appendString("--\(boundary)\r\n")
            body.appendString("Content-Disposition: form-data; name=\"response_format\"\r\n\r\n")
            body.appendString("json\r\n")
        } else {
            // whisper-1ã¯verbose_jsonã¨timestamp_granularitiesã‚’ã‚µãƒãƒ¼ãƒˆ
            print("ğŸ”µ Using verbose_json response format for whisper-1 model")
            body.appendString("--\(boundary)\r\n")
            body.appendString("Content-Disposition: form-data; name=\"response_format\"\r\n\r\n")
            body.appendString("verbose_json\r\n")
            
            // ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æœ‰åŠ¹åŒ–ï¼ˆé…åˆ—ã®å„è¦ç´ ã‚’å€‹åˆ¥ã«é€ä¿¡ï¼‰
            body.appendString("--\(boundary)\r\n")
            body.appendString("Content-Disposition: form-data; name=\"timestamp_granularities[]\"\r\n\r\n")
            body.appendString("word\r\n")
            
            body.appendString("--\(boundary)\r\n")
            body.appendString("Content-Disposition: form-data; name=\"timestamp_granularities[]\"\r\n\r\n")
            body.appendString("segment\r\n")
        }
        
        body.appendString("--\(boundary)--\r\n")
        
        request.httpBody = body
        
        // ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ¦‚è¦ã‚’ãƒ­ã‚°å‡ºåŠ›
        print("ğŸ”µ Request summary:")
        print("   - Endpoint: \(baseURL)")
        print("   - Model: \(model)")
        if let language = language {
            print("   - Language: \(language) (explicit)")
        } else {
            print("   - Language: nil (auto-detect mode)")
        }
        print("   - Body size: \(body.count) bytes")
        
        status = "Processing with OpenAI..."
        progress = 0.5
        
        print("ğŸ”µ Sending request to OpenAI API...")
        let (data, response) = try await URLSession.shared.data(for: request)
        print("ğŸ”µ Received response from OpenAI API")
        
        guard let httpResponse = response as? HTTPURLResponse else {
            print("âŒ Invalid response type")
            throw TranCriptionError.invalidResponse
        }
        
        print("ğŸ”µ HTTP status code: \(httpResponse.statusCode)")
        
        guard httpResponse.statusCode == 200 else {
            let errorMessage = String(data: data, encoding: .utf8) ?? "Unknown error"
            print("âŒ API error \(httpResponse.statusCode): \(errorMessage)")
            
            // è©³ç´°ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼ˆcheck-list.mdã«åŸºã¥ãï¼‰
            switch httpResponse.statusCode {
            case 401:
                print("âŒ Unauthorized: Invalid API key")
                throw TranCriptionError.apiError(401, "Invalid API key. Please check your OpenAI API key.")
            case 403:
                print("âŒ Forbidden: Model access denied")
                print("ğŸ” Make sure your API key has access to \(model) model.")
                print("ğŸ” Available models: whisper-1, gpt-4o-transcribe")
                print("ğŸ” You may need to enable the model in your OpenAI dashboard or use a different model.")
                throw TranCriptionError.apiError(403, "Model '\(model)' access denied. Please check your OpenAI API key permissions. Available models: whisper-1, gpt-4o-transcribe. You may need to select a different model or enable this model in your OpenAI dashboard.")
            case 413:
                print("âŒ Payload Too Large: File size exceeds limit")
                throw TranCriptionError.apiError(413, "Audio file is too large. Please use a file smaller than 25MB.")
            case 404:
                print("âŒ Model not found: \(model)")
                throw TranCriptionError.apiError(404, "Model '\(model)' not found. Please check the model name and ensure it's available in your account.")
            default:
                print("âŒ API Error \(httpResponse.statusCode): \(errorMessage)")
                throw TranCriptionError.apiError(httpResponse.statusCode, errorMessage)
            }
        }
        
        status = "Parsing response..."
        progress = 0.8
        
        let tranCriptionResponse = try JSONDecoder().decode(OpenAITranCriptionResponse.self, from: data)
        
        print("ğŸ”µ OpenAI API Response:")
        print("   - Detected language: \(tranCriptionResponse.language ?? "unknown")")
        print("   - Text preview: \(String(tranCriptionResponse.text.prefix(100)))...")
        print("   - Duration: \(tranCriptionResponse.duration ?? 0.0)s")
        print("   - Segments count: \(tranCriptionResponse.segments?.count ?? 0)")
        
        return TranCriptionResult(
            text: tranCriptionResponse.text,
            segments: tranCriptionResponse.segments?.map { segment in
                TranCriptionSegment(
                    start: segment.start,
                    end: segment.end,
                    text: segment.text
                )
            } ?? [],
            language: tranCriptionResponse.language ?? "unknown",
            duration: tranCriptionResponse.duration ?? 0.0
        )
    }
    
    private func performTranslation(audioData: Data, model: String) async throws -> TranCriptionResult {
        print("ğŸ”µ OpenAI Translation API call starting - model: \(model), audioData size: \(audioData.count) bytes")
        print("âš ï¸ TRANSLATION MODE: Output will always be in English")
        
        let translationURL = "https://api.openai.com/v1/audio/translations"
        
        guard let url = URL(string: translationURL) else {
            print("âŒ Invalid URL: \(translationURL)")
            throw TranCriptionError.invalidURL
        }
        
        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.setValue("Bearer \(apiKey)", forHTTPHeaderField: "Authorization")
        print("ğŸ”µ API request prepared - URL: \(translationURL)")
        
        // ãƒãƒ«ãƒãƒ‘ãƒ¼ãƒˆãƒ•ã‚©ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        let boundary = "Boundary-\(UUID().uuidString)"
        request.setValue("multipart/form-data; boundary=\(boundary)", forHTTPHeaderField: "Content-Type")
        
        var body = Data()
        
        // ãƒ¢ãƒ‡ãƒ«æŒ‡å®š
        body.appendString("--\(boundary)\r\n")
        body.appendString("Content-Disposition: form-data; name=\"model\"\r\n\r\n")
        body.appendString("\(model)\r\n")
        
        // ãƒ•ã‚¡ã‚¤ãƒ«éƒ¨åˆ†
        let (filename, mimeType) = detectAudioFormat(from: audioData)
        body.appendString("--\(boundary)\r\n")
        body.appendString("Content-Disposition: form-data; name=\"file\"; filename=\"\(filename)\"\r\n")
        body.appendString("Content-Type: \(mimeType)\r\n\r\n")
        body.append(audioData)
        body.appendString("\r\n")
        
        // ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼æŒ‡å®šï¼ˆtranslationsã¯verbose_jsonã‚’ã‚µãƒãƒ¼ãƒˆã—ãªã„ï¼‰
        body.appendString("--\(boundary)\r\n")
        body.appendString("Content-Disposition: form-data; name=\"response_format\"\r\n\r\n")
        body.appendString("json\r\n")
        
        body.appendString("--\(boundary)--\r\n")
        
        request.httpBody = body
        
        status = "Processing translation with OpenAI..."
        progress = 0.5
        
        print("ğŸ”µ Sending request to OpenAI Translation API...")
        let (data, response) = try await URLSession.shared.data(for: request)
        print("ğŸ”µ Received response from OpenAI Translation API")
        
        guard let httpResponse = response as? HTTPURLResponse else {
            print("âŒ Invalid response type")
            throw TranCriptionError.invalidResponse
        }
        
        print("ğŸ”µ HTTP status code: \(httpResponse.statusCode)")
        
        guard httpResponse.statusCode == 200 else {
            let errorMessage = String(data: data, encoding: .utf8) ?? "Unknown error"
            print("âŒ API error \(httpResponse.statusCode): \(errorMessage)")
            
            switch httpResponse.statusCode {
            case 401:
                print("âŒ Unauthorized: Invalid API key")
                throw TranCriptionError.apiError(401, "Invalid API key. Please check your OpenAI API key.")
            case 403:
                print("âŒ Forbidden: Model access denied")
                throw TranCriptionError.apiError(403, "Model '\(model)' access denied. Note: Translations only support whisper-1 model.")
            case 413:
                print("âŒ Payload Too Large: File size exceeds limit")
                throw TranCriptionError.apiError(413, "Audio file is too large. Please use a file smaller than 25MB.")
            case 404:
                print("âŒ Model not found: \(model)")
                throw TranCriptionError.apiError(404, "Model '\(model)' not found. Translations only support whisper-1 model.")
            default:
                print("âŒ API Error \(httpResponse.statusCode): \(errorMessage)")
                throw TranCriptionError.apiError(httpResponse.statusCode, errorMessage)
            }
        }
        
        status = "Parsing response..."
        progress = 0.8
        
        // ç¿»è¨³APIã¯ã‚·ãƒ³ãƒ—ãƒ«ãªJSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ã¿ã‚’è¿”ã™
        let translationResponse = try JSONDecoder().decode(OpenAITranslationResponse.self, from: data)
        
        return TranCriptionResult(
            text: translationResponse.text,
            segments: [],
            language: "en",  // ç¿»è¨³ã¯å¸¸ã«è‹±èª
            duration: 0.0
        )
    }
    
    // MARK: - Helper Methods
    
    private func getLanguagePrompt(for languageCode: String) -> String {
        // è¨€èªã‚³ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦ã€ãƒ¢ãƒ‡ãƒ«ã«å‡ºåŠ›è¨€èªã‚’æŒ‡ç¤ºã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
        // OpenAI WhisperãŒå¯¾å¿œã™ã‚‹99è¨€èªå…¨ã¦ã‚’ã‚«ãƒãƒ¼
        let languagePrompts: [String: String] = [
            // ä¸»è¦è¨€èª
            "en": "The following is English audio.",
            "zh": "ä»¥ä¸‹æ˜¯ä¸­æ–‡è¯­éŸ³ã€‚",
            "de": "Das Folgende ist Audio auf Deutsch.",
            "es": "El siguiente es audio en espaÃ±ol.",
            "ru": "Ğ¡Ğ»ĞµĞ´ÑƒÑÑ‰ĞµĞµ - Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ.",
            "ko": "ë‹¤ìŒì€ í•œêµ­ì–´ ìŒì„±ì…ë‹ˆë‹¤.",
            "fr": "Ce qui suit est un audio en franÃ§ais.",
            "ja": "èª¤å­—è„±å­—ã¯ä¿®æ­£",
            "pt": "O seguinte Ã© Ã¡udio em portuguÃªs.",
            "tr": "AÅŸaÄŸÄ±daki TÃ¼rkÃ§e sestir.",
            
            // ãƒ¨ãƒ¼ãƒ­ãƒƒãƒ‘è¨€èª
            "pl": "PoniÅ¼ej znajduje siÄ™ nagranie w jÄ™zyku polskim.",
            "ca": "El segÃ¼ent Ã©s Ã udio en catalÃ .",
            "nl": "Het volgende is audio in het Nederlands.",
            "sv": "FÃ¶ljande Ã¤r ljud pÃ¥ svenska.",
            "it": "Il seguente Ã¨ audio in italiano.",
            "fi": "Seuraava on Ã¤Ã¤ni suomeksi.",
            "uk": "ĞĞ¸Ğ¶Ñ‡Ğµ Ğ½Ğ°Ğ²ĞµĞ´ĞµĞ½Ğ¾ Ğ°ÑƒĞ´Ñ–Ğ¾ ÑƒĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ¾Ñ Ğ¼Ğ¾Ğ²Ğ¾Ñ.",
            "el": "Î‘ÎºÎ¿Î»Î¿Ï…Î¸ÎµÎ¯ Î®Ï‡Î¿Ï‚ ÏƒÏ„Î± ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬.",
            "cs": "NÃ¡sledujÃ­cÃ­ je audio v ÄeÅ¡tinÄ›.",
            "ro": "UrmÄƒtorul este audio Ã®n romÃ¢nÄƒ.",
            "da": "FÃ¸lgende er lyd pÃ¥ dansk.",
            "hu": "A kÃ¶vetkezÅ‘ hang magyarul.",
            "no": "FÃ¸lgende er lyd pÃ¥ norsk.",
            "hr": "SljedeÄ‡i je audio na hrvatskom.",
            "bg": "Ğ¡Ğ»ĞµĞ´Ğ²Ğ°Ñ‰Ğ¾Ñ‚Ğ¾ Ğµ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ½Ğ° Ğ±ÑŠĞ»Ğ³Ğ°Ñ€ÑĞºĞ¸.",
            "lt": "Toliau pateikiamas garsas lietuviÅ³ kalba.",
            "la": "Sequens est audio in Latina.",
            "cy": "Mae'r canlynol yn sain yn Gymraeg.",
            "sk": "NasledujÃºci je zvuk v slovenÄine.",
            "lv": "TÄlÄk ir audio latvieÅ¡u valodÄ.",
            "sr": "Ğ¡Ğ»ĞµĞ´ĞµÑ›Ğµ Ñ˜Ğµ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ½Ğ° ÑÑ€Ğ¿ÑĞºĞ¾Ğ¼.",
            "sl": "Naslednji je zvok v slovenÅ¡Äini.",
            "et": "JÃ¤rgnev on heli eesti keeles.",
            "mk": "Ğ¡Ğ»ĞµĞ´Ğ½Ğ¾Ğ²Ğ¾ Ğµ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ½Ğ° Ğ¼Ğ°ĞºĞµĞ´Ğ¾Ğ½ÑĞºĞ¸.",
            "br": "Ar pezh a zeu a zo son e brezhoneg.",
            "eu": "Hurrengoa euskarazko audioa da.",
            "is": "Eftirfarandi er hljÃ³Ã° Ã¡ Ã­slensku.",
            "nn": "FÃ¸lgjande er lyd pÃ¥ nynorsk.",
            "mt": "Li jmiss huwa awdjo bil-Malti.",
            "lb": "DÃ©i folgend ass Audio op LÃ«tzebuergesch.",
            
            // ä¸­æ±ãƒ»å—ã‚¢ã‚¸ã‚¢è¨€èª
            "ar": "Ø§Ù„ØªØ§Ù„ÙŠ Ù‡Ùˆ ØµÙˆØª Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.",
            "he": "×œ×”×œ×Ÿ ×©××¢ ×‘×¢×‘×¨×™×ª.",
            "fa": "Ù…ÙˆØ§Ø±Ø¯ Ø²ÛŒØ± ØµØ¯Ø§ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø§Ø³Øª.",
            "ur": "Ù…Ù†Ø¯Ø±Ø¬Û Ø°ÛŒÙ„ Ø§Ø±Ø¯Ùˆ Ø¢ÚˆÛŒÙˆ ÛÛ’Û”",
            "ps": "Ù„Ø§Ù†Ø¯Û Ù¾Ù‡ Ù¾ÚšØªÙˆ Ú©Û ØºÚ– Ø¯ÛŒ.",
            "sd": "Ù‡ÙŠÙº ÚÙ†Ù„ Ø³Ù†ÚŒÙŠ Ø¢ÚŠÙŠÙˆ Ø¢Ù‡ÙŠ.",
            
            // å—ã‚¢ã‚¸ã‚¢ãƒ»æ±å—ã‚¢ã‚¸ã‚¢è¨€èª
            "hi": "à¤¨à¤¿à¤®à¥à¤¨à¤²à¤¿à¤–à¤¿à¤¤ à¤¹à¤¿à¤‚à¤¦à¥€ à¤‘à¤¡à¤¿à¤¯à¥‹ à¤¹à¥ˆà¥¤",
            "th": "à¸•à¹ˆà¸­à¹„à¸›à¸™à¸µà¹‰à¹€à¸›à¹‡à¸™à¹€à¸ªà¸µà¸¢à¸‡à¸ à¸²à¸©à¸²à¹„à¸—à¸¢",
            "vi": "Sau Ä‘Ã¢y lÃ  Ã¢m thanh tiáº¿ng Viá»‡t.",
            "id": "Berikut adalah audio dalam bahasa Indonesia.",
            "ms": "Berikut adalah audio dalam Bahasa Melayu.",
            "ta": "à®ªà®¿à®©à¯à®µà®°à¯à®µà®¤à¯ à®¤à®®à®¿à®´à¯ à®†à®Ÿà®¿à®¯à¯‹ à®†à®•à¯à®®à¯.",
            "ml": "à´¤à´¾à´´àµ† à´•àµŠà´Ÿàµà´¤àµà´¤à´¿à´°à´¿à´•àµà´•àµà´¨àµà´¨à´¤àµ à´®à´²à´¯à´¾à´³à´‚ à´“à´¡à´¿à´¯àµ‹ à´†à´£àµ.",
            "te": "à°•à±à°°à°¿à°‚à°¦à°¿ à°¤à±†à°²à±à°—à± à°†à°¡à°¿à°¯à±‹.",
            "kn": "à²ˆ à²•à³†à²³à²—à²¿à²¨ à²•à²¨à³à²¨à²¡ à²†à²¡à²¿à²¯à³‹.",
            "mr": "à¤–à¤¾à¤²à¥€à¤² à¤®à¤°à¤¾à¤ à¥€ à¤‘à¤¡à¤¿à¤“ à¤†à¤¹à¥‡.",
            "gu": "àª¨à«€àªšà«‡ àª—à«àªœàª°àª¾àª¤à«€ àª“àª¡àª¿àª¯à«‹ àª›à«‡.",
            "bn": "à¦¨à¦¿à¦®à§à¦¨à¦²à¦¿à¦–à¦¿à¦¤ à¦¬à¦¾à¦‚à¦²à¦¾ à¦…à¦¡à¦¿à¦¯à¦¼à§‹à¥¤",
            "pa": "à¨¹à©‡à¨ à¨¾à¨‚ à¨ªà©°à¨œà¨¾à¨¬à©€ à¨†à¨¡à©€à¨“ à¨¹à©ˆà¥¤",
            "si": "à¶´à·„à¶­ à·ƒà·’à¶‚à·„à¶½ à·à·Šâ€à¶»à·€à·Šâ€à¶º à·€à·š.",
            "km": "áá¶á„á€áŸ’ášáŸ„á˜á‚áºá‡á¶áŸáŸ†á¡áŸá„á—á¶áŸá¶ááŸ’á˜áŸ‚ášáŸ”",
            "lo": "àº•à»à»ˆà»„àº›àº™àºµà»‰à»àº¡à»ˆàº™àºªàº½àº‡àºàº²àºªàº²àº¥àº²àº§.",
            "my": "á€¡á€±á€¬á€€á€ºá€•á€«á€™á€¾á€¬ á€™á€¼á€”á€ºá€™á€¬ á€¡á€á€¶ á€–á€¼á€…á€ºá€•á€«á€á€šá€ºá‹",
            "ne": "à¤¨à¤¿à¤®à¥à¤¨ à¤¨à¥‡à¤ªà¤¾à¤²à¥€ à¤…à¤¡à¤¿à¤¯à¥‹ à¤¹à¥‹à¥¤",
            "as": "à¦¤à¦²à¦¤ à¦…à¦¸à¦®à§€à¦¯à¦¼à¦¾ à¦…à¦¡à¦¿à¦…' à¦†à¦›à§‡à¥¤",
            "tl": "Ang sumusunod ay audio sa Tagalog.",
            "jw": "Ing ngisor iki audio ing basa Jawa.",
            "su": "Ieu di handap audio dina basa Sunda.",
            
            // æ±ã‚¢ã‚¸ã‚¢è¨€èª
            "yue": "ä»¥ä¸‹ä¿‚ç²µèªèªéŸ³ã€‚",
            "mn": "Ğ”Ğ°Ñ€Ğ°Ğ°Ñ… Ğ½ÑŒ Ğ¼Ğ¾Ğ½Ğ³Ğ¾Ğ» Ñ…ÑĞ» Ğ´ÑÑÑ€Ñ… Ğ°ÑƒĞ´Ğ¸Ğ¾ ÑĞ¼.",
            "bo": "à½ à½‘à½²à¼‹à½“à½²à¼‹à½–à½¼à½‘à¼‹à½€à¾±à½²à¼‹à½¦à¾’à¾²à¼‹à½¡à½²à½“à¼",
            
            // ãã®ä»–ã®ã‚¢ã‚¸ã‚¢ãƒ»å¤ªå¹³æ´‹è¨€èª
            "hy": "Õ€Õ¥Õ¿Ö‡ÕµÕ¡Õ¬Õ¶ Õ§ Õ°Õ¡ÕµÕ¥Ö€Õ¥Õ¶ Õ¡Õ¸Ö‚Õ¤Õ«Õ¸Ö‰",
            "az": "AÅŸaÄŸÄ±dakÄ± azÉ™rbaycan dilindÉ™ sÉ™sdir.",
            "be": "ĞĞ°ÑÑ‚ÑƒĞ¿Ğ½Ñ‹ - Ğ°ÑĞ´Ñ‹Ñ‘ Ğ½Ğ° Ğ±ĞµĞ»Ğ°Ñ€ÑƒÑĞºĞ°Ğ¹ Ğ¼Ğ¾Ğ²Ğµ.",
            "bs": "SljedeÄ‡e je audio na bosanskom.",
            "ka": "áƒ¨áƒ”áƒ›áƒ“áƒ”áƒ’áƒ˜ áƒáƒ áƒ˜áƒ¡ áƒáƒ£áƒ“áƒ˜áƒ áƒ¥áƒáƒ áƒ—áƒ£áƒšáƒáƒ“.",
            "kk": "Ğ¢Ó©Ğ¼ĞµĞ½Ğ´Ğµ Ò›Ğ°Ğ·Ğ°Ò›ÑˆĞ° Ğ°ÑƒĞ´Ğ¸Ğ¾.",
            "tg": "Ğ—ĞµÑ€Ğ¸Ğ½ ÑĞ°Ğ´Ğ¾Ğ¸ Ñ‚Ğ¾Ò·Ğ¸ĞºÓ£ Ğ°ÑÑ‚.",
            "uz": "Quyida o'zbek tilida audio.",
            "tk": "AÅŸakdaky tÃ¼rkmen dilinde ses.",
            "tt": "Ğ¢Ò¯Ğ±Ó™Ğ½Ğ´Ó™ Ñ‚Ğ°Ñ‚Ğ°Ñ€ Ñ‚ĞµĞ»ĞµĞ½Ğ´Ó™ Ğ°ÑƒĞ´Ğ¸Ğ¾.",
            "ba": "ĞšĞ¸Ğ»Ó™Ò»Ğµ Ğ±Ğ°ÑˆÒ¡Ğ¾Ñ€Ñ‚ Ñ‚ĞµĞ»ĞµĞ½Ğ´Ó™ Ğ°ÑƒĞ´Ğ¸Ğ¾.",
            
            // ã‚¢ãƒ•ãƒªã‚«è¨€èª
            "af": "Die volgende is klank in Afrikaans.",
            "sw": "Ifuatayo ni sauti katika Kiswahili.",
            "am": "áŠ¨á‹šáˆ… á‰ á‰³á‰½ á‰ áŠ áˆ›áˆ­áŠ› á‹¨á‹µáˆáŒ½ áŠá‹á¢",
            "ha": "Mai zuwa yana sauti a Hausa.",
            "yo": "Atáº¹le jáº¹ ohun ni ede Yoruba.",
            "so": "Soo socda waa cod Soomaali ah.",
            "sn": "Zvinotevera ndiyo inzwi muchiShona.",
            "mg": "Izay manaraka dia feo amin'ny teny Malagasy.",
            "ln": "Oyo elandi ezali mongongo na Lingala.",
            
            // ãã®ä»–ã®è¨€èª
            "mi": "Ko te mea e whai ake nei he oro i te reo MÄori.",
            "sq": "Sa vijon Ã«shtÃ« audio nÃ« shqip.",
            "gl": "O seguinte Ã© audio en galego.",
            "oc": "Lo seguent es Ã udio en occitan.",
            "fo": "Fylgjandi er ljÃ³Ã° Ã¡ fÃ¸royskt.",
            "ht": "Sa ki annapre a se odyo an kreyÃ²l ayisyen.",
            "sa": "à¤…à¤§à¤ƒ à¤¸à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤®à¥ à¤‘à¤¡à¤¿à¤¯à¥‹ à¤…à¤¸à¥à¤¤à¤¿à¥¤",
            "yi": "×“×™ ×¤Ö¿×Ö¸×œ×’× ×“×¢ ××™×– ×Ö·×•×“×™×Ö¸ ××•×™×£ ×™×™Ö´×“×™×©.",
            "haw": "Ê»O ka mea e hiki mai nei he leo Ê»Ålelo HawaiÊ»i."
        ]
        
        // è¨€èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€è‹±èªã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if let prompt = languagePrompts[languageCode] {
            return prompt
        } else {
            print("âš ï¸ No specific prompt for language code '\(languageCode)', using fallback")
            return "The following is audio in \(languageCode) language."
        }
    }
    
    private func detectAudioFormat(from audioData: Data) -> (filename: String, mimeType: String) {
        // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬æ¤œè¨¼
        guard !audioData.isEmpty else {
            print("âŒ Cannot detect format: audio data is empty")
            return ("audio.mp3", "audio/mpeg") // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        }
        
        // ãƒã‚¸ãƒƒã‚¯ãƒã‚¤ãƒˆã§ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’æ¤œå‡º
        let prefix = audioData.prefix(12)
        
        // MP3 (starts with FF FB or FF F3 or FF F2 or ID3)
        if prefix.count >= 2 {
            if prefix[0] == 0xFF && (prefix[1] & 0xE0) == 0xE0 {
                print("ğŸ” Detected audio format: MP3")
                return ("audio.mp3", "audio/mpeg")
            }
        }
        
        if prefix.count >= 3 {
            if prefix[0] == 0x49 && prefix[1] == 0x44 && prefix[2] == 0x33 {  // ID3
                print("ğŸ” Detected audio format: MP3 with ID3 tag")
                return ("audio.mp3", "audio/mpeg")
            }
        }
        
        // M4A/MP4 (starts with ftyp)
        if prefix.count >= 8 {
            if prefix[4] == 0x66 && prefix[5] == 0x74 && prefix[6] == 0x79 && prefix[7] == 0x70 {
                print("ğŸ” Detected audio format: M4A/MP4")
                return ("audio.m4a", "audio/mp4")
            }
        }
        
        // WAV (starts with RIFF....WAVE)
        if prefix.count >= 12 {
            if prefix[0] == 0x52 && prefix[1] == 0x49 && prefix[2] == 0x46 && prefix[3] == 0x46 &&
               prefix[8] == 0x57 && prefix[9] == 0x41 && prefix[10] == 0x56 && prefix[11] == 0x45 {
                print("ğŸ” Detected audio format: WAV")
                return ("audio.wav", "audio/wav")
            }
        }
        
        // FLAC (starts with fLaC)
        if prefix.count >= 4 {
            if prefix[0] == 0x66 && prefix[1] == 0x4C && prefix[2] == 0x61 && prefix[3] == 0x43 {
                print("ğŸ” Detected audio format: FLAC")
                return ("audio.flac", "audio/flac")
            }
        }
        
        // OGG (starts with OggS)
        if prefix.count >= 4 {
            if prefix[0] == 0x4F && prefix[1] == 0x67 && prefix[2] == 0x67 && prefix[3] == 0x53 {
                print("ğŸ” Detected audio format: OGG")
                return ("audio.ogg", "audio/ogg")
            }
        }
        
        // WebM (starts with 0x1A 0x45 0xDF 0xA3)
        if prefix.count >= 4 {
            if prefix[0] == 0x1A && prefix[1] == 0x45 && prefix[2] == 0xDF && prefix[3] == 0xA3 {
                print("ğŸ” Detected audio format: WebM")
                return ("audio.webm", "audio/webm")
            }
        }
        
        // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯MP3ã¨ã—ã¦æ‰±ã†ï¼ˆæœ€ã‚‚ä¸€èˆ¬çš„ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼‰
        print("âš ï¸ Unknown audio format, defaulting to MP3")
        return ("audio.mp3", "audio/mpeg")
    }
}

// MARK: - Supporting Types


// MARK: - TranCription Service Supporting Types

// MARK: - OpenAI API Response Models

private struct OpenAITranCriptionResponse: Codable {
    let text: String
    let language: String?
    let duration: Double?
    let segments: [OpenAISegment]?
}

private struct OpenAITranslationResponse: Codable {
    let text: String
}

private struct OpenAISegment: Codable {
    let start: Double
    let end: Double
    let text: String
}

// MARK: - Data Extension for String Appending

extension Data {
    mutating func appendString(_ string: String) {
        if let data = string.data(using: .utf8) {
            append(data)
        }
    }
}

