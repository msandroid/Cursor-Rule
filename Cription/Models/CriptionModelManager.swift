//  For licensing see accompanying LICENSE.md file.
//  Copyright Â© 2025 Cription. All rights reserved.

import Foundation
import SwiftUI
import WhisperKit

@MainActor
class WhisperModelManager: ObservableObject {
    @Published var selectedModel: String = "openai_whisper-base"
    @Published var localModels: [String] = []
    @Published var isOptimizing: Bool = false
    @Published var optimizationProgress: Double = 0.0
    @Published var optimizationStatus: String = ""
    @Published var whisperKit: WhisperKit?
    @Published var modelState: ModelState = .unloaded
    
    private let whisperModels = WhisperModels.shared
    private let repoName = "argmaxinc/whisperkit-coreml"
    
    // é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®è¡¨ç¤ºåã‚’å–å¾—
    var selectedModelDisplayName: String {
        if let model = whisperModels.getModel(by: selectedModel) {
            return model.displayName
        }
        return selectedModel.components(separatedBy: "_").dropFirst().joined(separator: " ")
    }
    
    init() {
        print("ğŸš€ WhisperModelManager initializing")
        setupCustomLogging()
        
        // ãƒãƒ³ãƒ‰ãƒ«å†…ã®ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ¤œç´¢ã—ã¦ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆã«è¿½åŠ 
        print("Scanning for bundled models")
        
        let bundledModelIds = findAllBundledModels()
        
        if !bundledModelIds.isEmpty {
            print("âœ… Found \(bundledModelIds.count) bundled models: \(bundledModelIds)")
            localModels.append(contentsOf: bundledModelIds)
        } else {
            print("âš ï¸ No bundled models found")
            optimizationStatus = "No bundled models found. Please select a model manually."
        }
        
        // ãƒãƒ³ãƒ‰ãƒ«ã•ã‚Œã¦ã„ã‚‹æœ€åˆã®ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•é¸æŠï¼ˆãƒ¢ãƒ‡ãƒ«IDã‚’ä½¿ç”¨ï¼‰
        if let firstBundledModelId = localModels.first {
            selectedModel = firstBundledModelId
            print("Set selectedModel to first bundled model ID: \(selectedModel) (\(selectedModelDisplayName))")
        } else {
            print("âš ï¸ No bundled models found")
        }
        print("Current localModels (IDs): \(localModels)")
        
        // ãƒãƒ³ãƒ‰ãƒ«ãƒ¢ãƒ‡ãƒ«ã®å­˜åœ¨ç¢ºèª
        if !localModels.isEmpty {
            print("âœ… \(localModels.count) bundled models available for auto-loading")
        } else {
            print("âš ï¸ No bundled models found, will attempt manual detection")
        }
        
        // åˆæœŸåŒ–å®Œäº†æ™‚ã®çŠ¶æ…‹ã‚’ãƒ­ã‚°å‡ºåŠ›
        print("ğŸ”„ WhisperModelManager initialization completed")
        print("ğŸ”„ Model state: \(modelState)")
        print("ğŸ”„ Selected model: \(selectedModel)")
        print("ğŸ”„ Local models: \(localModels)")
        print("ğŸ”„ Auto-load will be triggered on app appear")
    }
    
    // ã™ã¹ã¦ã®ãƒãƒ³ãƒ‰ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’æ¤œç´¢ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
    func findAllBundledModels() -> [String] {
        print("ğŸ” Starting comprehensive bundled model search")
        
        var foundModelIds: [String] = []
        
        // 1. ãƒãƒ³ãƒ‰ãƒ«ã•ã‚Œã¦ã„ã‚‹å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ¤œç´¢ï¼ˆãƒ¢ãƒ‡ãƒ«IDã¨è¡¨ç¤ºåã®ä¸¡æ–¹ã§æ¤œç´¢ï¼‰
        let bundledModelInfo: [(id: String, displayName: String)] = [
            ("openai_whisper-base", "Cription mini"),
            ("openai_whisper-tiny.en", "Cription Swift English"),
            ("openai_whisper-base.en", "Cription mini English")
        ]
        
        for modelInfo in bundledModelInfo {
            // ã¾ãšBundle.main.path()ã‚’ä½¿ç”¨ã—ã¦ãƒªã‚½ãƒ¼ã‚¹ã‚’æ¤œç´¢
            if let modelPath = Bundle.main.path(forResource: modelInfo.displayName, ofType: nil) {
                print("ğŸ“ Found bundled model by display name: \(modelInfo.displayName) at \(modelPath)")
                if isValidModelDirectory(modelPath) {
                    foundModelIds.append(modelInfo.id)
                    print("âœ… \(modelInfo.displayName) is a valid model directory (ID: \(modelInfo.id))")
                } else {
                    print("âŒ \(modelInfo.displayName) directory exists but is not a valid model")
                }
            } else if let modelPath = Bundle.main.path(forResource: modelInfo.id, ofType: nil) {
                print("ğŸ“ Found bundled model by ID: \(modelInfo.id) at \(modelPath)")
                if isValidModelDirectory(modelPath) {
                    foundModelIds.append(modelInfo.id)
                    print("âœ… \(modelInfo.id) is a valid model directory")
                } else {
                    print("âŒ \(modelInfo.id) directory exists but is not a valid model")
                }
            } else {
                // Bundle APIã§è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€Resourcesãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç›´æ¥æ¤œç´¢
                var foundPath: String? = nil
                
                // 1. resourcePathç›´ä¸‹ã‚’æ¤œç´¢
                if let resourcePath = Bundle.main.resourcePath {
                    let modelPath = "\(resourcePath)/\(modelInfo.displayName)"
                    if FileManager.default.fileExists(atPath: modelPath) {
                        print("ğŸ“ Found model in Resources directory: \(modelInfo.displayName) at \(modelPath)")
                        foundPath = modelPath
                    }
                }
                
                // 2. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®Resourcesãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¤œç´¢
                if foundPath == nil {
                    let projectPath = Bundle.main.bundlePath
                    let paths = [
                        "\(projectPath)/../Cription/Resources/\(modelInfo.displayName)",
                        "\(projectPath)/../../Cription/Resources/\(modelInfo.displayName)",
                        "\(projectPath)/../../../Cription/Resources/\(modelInfo.displayName)"
                    ]
                    
                    for path in paths {
                        let normalizedPath = (path as NSString).standardizingPath
                        if FileManager.default.fileExists(atPath: normalizedPath) {
                            print("ğŸ“ Found model in project Resources: \(modelInfo.displayName) at \(normalizedPath)")
                            foundPath = normalizedPath
                            break
                        }
                    }
                }
                
                // æ¤œè¨¼ã—ã¦è¿½åŠ 
                if let path = foundPath {
                    if isValidModelDirectory(path) {
                        foundModelIds.append(modelInfo.id)
                        print("âœ… \(modelInfo.displayName) is a valid model directory (ID: \(modelInfo.id))")
                    } else {
                        print("âŒ \(modelInfo.displayName) directory exists but is not a valid model")
                    }
                } else {
                    print("âš ï¸ Model \(modelInfo.displayName) not found in any Resources location")
                }
            }
        }
        
        print("ğŸ“Š Total bundled models found: \(foundModelIds.count)")
        print("ğŸ“Š Model IDs: \(foundModelIds)")
        
        // ãƒ¢ãƒ‡ãƒ«IDã‚’è¿”ã™ï¼ˆè¡¨ç¤ºåã«å¤‰æ›ã—ãªã„ï¼‰
        return foundModelIds
    }
    
    // ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒæœ‰åŠ¹ã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯
    private func isValidModelDirectory(_ path: String) -> Bool {
        let requiredFiles = [
            "AudioEncoder.mlmodelc/model.mil",
            "AudioEncoder.mlmodelc/weights/weight.bin",
            "MelSpectrogram.mlmodelc/model.mil",
            "MelSpectrogram.mlmodelc/weights/weight.bin",
            "TextDecoder.mlmodelc/model.mil",
            "TextDecoder.mlmodelc/weights/weight.bin",
            "config.json"
        ]
        
        for file in requiredFiles {
            let fullPath = "\(path)/\(file)"
            if !FileManager.default.fileExists(atPath: fullPath) {
                print("Missing required file: \(file) at \(fullPath)")
                return false
            }
            
            // ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ï¼ˆç©ºãƒ•ã‚¡ã‚¤ãƒ«ã§ãªã„ã‹ï¼‰
            do {
                let attributes = try FileManager.default.attributesOfItem(atPath: fullPath)
                if let fileSize = attributes[.size] as? Int64, fileSize == 0 {
                    print("Empty file detected: \(file)")
                    return false
                }
            } catch {
                print("Error checking file attributes for \(file): \(error.localizedDescription)")
                return false
            }
        }
        
        return true
    }
    
    func addLocalModel(_ model: String) {
        if !localModels.contains(model) {
            localModels.append(model)
        }
    }
    
    func removeLocalModel(_ model: String) {
        localModels.removeAll { $0 == model }
    }
    
    // ãƒ¢ãƒ‡ãƒ«é¸æŠæ™‚ã®è‡ªå‹•ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½
    func selectModel(_ model: String) {
        selectedModel = model
        // æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•ã§ãƒ­ãƒ¼ãƒ‰
        Task {
            await loadModel(model)
        }
    }
    
    // ãƒ¢ãƒ‡ãƒ«å‰Šé™¤æ©Ÿèƒ½
    func deleteModel(_ model: String) async {
        // ãƒãƒ³ãƒ‰ãƒ«ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯å‰Šé™¤ã§ããªã„
        if isBundledModel(model) {
            optimizationStatus = "Cannot delete bundled model"
            return
        }
        
        // ã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯
        let subscriptionManager = SubCriptionManager.shared
        
        // æœ‰æ–™ãƒ—ãƒ©ãƒ³åŠ å…¥ä¸­ã§ãªã„ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¯å‰Šé™¤ï¼ˆOpenAIãƒ¢ãƒ‡ãƒ«ã®ã¿ï¼‰
        if !subscriptionManager.isSubCriptiond && isOpenAIModel(model) {
            if selectedModel == model {
                // ç¾åœ¨é¸æŠã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’å‰Šé™¤ã™ã‚‹å ´åˆ
                whisperKit = nil
                modelState = .unloaded
                optimizationStatus = "Model deleted (subscription required)"
            }
            
            // ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰ã‚‚å‰Šé™¤
            await deleteModelFiles(model)
        }
    }
    
    // ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®Œå…¨ã«å‰Šé™¤
    private func deleteModelFiles(_ model: String) async {
        guard let documents = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask).first else {
            return
        }
        
        let modelPath = documents.appendingPathComponent("huggingface/models/argmaxinc/whisperkit-coreml").appendingPathComponent(model)
        
        do {
            if FileManager.default.fileExists(atPath: modelPath.path) {
                try FileManager.default.removeItem(at: modelPath)
                if let index = localModels.firstIndex(of: model) {
                    localModels.remove(at: index)
                }
                print("Successfully deleted model files for: \(model)")
            }
        } catch {
            print("Error deleting model files: \(error.localizedDescription)")
        }
    }
    
    // ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´åˆæ€§ã‚’ãƒã‚§ãƒƒã‚¯
    private func validateModelFiles(at modelPath: URL) async -> Bool {
        let requiredFiles = [
            "AudioEncoder.mlmodelc/model.mil",
            "AudioEncoder.mlmodelc/weights/weight.bin",
            "MelSpectrogram.mlmodelc/model.mil",
            "MelSpectrogram.mlmodelc/weights/weight.bin",
            "TextDecoder.mlmodelc/model.mil",
            "TextDecoder.mlmodelc/weights/weight.bin",
            "config.json"
        ]
        
        print("Validating model files at: \(modelPath.path)")
        
        for filePath in requiredFiles {
            let fullPath = modelPath.appendingPathComponent(filePath)
            
            // ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
            guard FileManager.default.fileExists(atPath: fullPath.path) else {
                print("âŒ Missing required file: \(filePath) at \(fullPath.path)")
                return false
            }
            
            // ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ï¼ˆç©ºãƒ•ã‚¡ã‚¤ãƒ«ã§ãªã„ã‹ï¼‰
            do {
                let attributes = try FileManager.default.attributesOfItem(atPath: fullPath.path)
                if let fileSize = attributes[.size] as? Int64 {
                    if fileSize == 0 {
                        print("âŒ Empty file detected: \(filePath) at \(fullPath.path)")
                        return false
                    }
                    print("âœ… File validated: \(filePath) (size: \(fileSize) bytes)")
                } else {
                    print("âŒ Could not determine file size for: \(filePath)")
                    return false
                }
            } catch {
                print("âŒ Error checking file attributes for \(filePath): \(error.localizedDescription)")
                return false
            }
        }
        
        print("âœ… Model files validation passed for: \(modelPath.path)")
        return true
    }
    
    // è¡¨ç¤ºåã‹ã‚‰å…ƒã®ãƒ¢ãƒ‡ãƒ«IDã«å¤‰æ›ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰
    private func getModelId(for displayName: String) -> String {
        // ãƒ¢ãƒ‡ãƒ«åãƒãƒƒãƒ”ãƒ³ã‚°
        let modelNameMap: [String: String] = [
            "Cription Swift English": "openai_whisper-tiny.en",
            "Cription mini English": "openai_whisper-base.en",
            "Cription Pro English": "openai_whisper-small.en",
            "Cription Enterprise English": "openai_whisper-medium.en",
            
            "Cription Swift": "openai_whisper-tiny",
            "Cription mini": "openai_whisper-base",
            "Cription Pro": "openai_whisper-small",
            "Cription Enterprise": "openai_whisper-medium",
            "Cription Ultra": "openai_whisper-large-v2",
            "Cription UltraTurbo": "openai_whisper-large-v2_turbo",
            
            "Quantum Cription English": "openai_whisper-small.en_217MB",
            "Quantum Cription mini": "openai_whisper-small_216MB",
            "Quantum Cription UltraLite 1.0": "openai_whisper-large-v2_949MB",
            "Quantum Cription UltraTurboLite 2.0": "openai_whisper-large-v2_turbo_955MB",
            "Quantum Cription UltraLite 3.0": "openai_whisper-large-v3_947MB",
            "Quantum Cription UltraTurboLite 3.5": "openai_whisper-large-v3_turbo_954MB",
            
            "Quantum Cription Ultra 3.6": "openai_whisper-large-v3-v20240930",
            "Quantum Cription UltraTurbo 3.6": "openai_whisper-large-v3-v20240930_turbo",
            "Quantum Cription UltraLite 3.6": "openai_whisper-large-v3-v20240930_547MB",
            "Quantum Cription UltraLite+ 3.6": "openai_whisper-large-v3-v20240930_626MB",
            "Quantum Cription UltraTurboLite 3.6": "openai_whisper-large-v3-v20240930_turbo_632MB",
            
            "Cription Dual 3.0": "distil-whisper_distil-large-v3",
            "Cription Dual 0.5": "distil-whisper_distil-large-v3_594MB",
            "Cription Dual 1.5": "distil-whisper_distil-large-v3_turbo",
            "Cription Dual 0.6": "distil-whisper_distil-large-v3_turbo_600MB"
        ]
        
        // ãƒãƒƒãƒ”ãƒ³ã‚°ã‹ã‚‰æ¤œç´¢
        if let modelId = modelNameMap[displayName] {
            return modelId
        }
        
        // WhisperModelsã‹ã‚‰æ¤œç´¢
        if let model = whisperModels.allModels.first(where: { $0.displayName == displayName }) {
            return model.id
        }
        
        // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: è¡¨ç¤ºåã‚’ãã®ã¾ã¾è¿”ã™
        return displayName
    }
    
    // ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½
    func loadModel(_ model: String, redownload: Bool = false) async {
        selectedModel = model
        modelState = .downloading
        optimizationProgress = 0.0
        optimizationStatus = "Starting model loading"
        
        // ã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ã¯åˆ¶é™è§£é™¤ï¼‰
        let subscriptionManager = SubCriptionManager.shared
        
        // ãƒãƒ³ãƒ‰ãƒ«ãƒ¢ãƒ‡ãƒ«ä»¥å¤–ã§ã€ã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ãŒãªã„å ´åˆã¯ãƒ­ãƒ¼ãƒ‰ä¸å¯ï¼ˆOpenAIãƒ¢ãƒ‡ãƒ«ã®ã¿ï¼‰
        if !isBundledModel(model) && isOpenAIModel(model) && !subscriptionManager.isSubCriptiond {
            modelState = .unloaded
            optimizationStatus = "Subscription required to use this model"
            print("âŒ Subscription required to load model: \(model)")
            return
        }
        
        // è¡¨ç¤ºåã‚’å…ƒã®ãƒ¢ãƒ‡ãƒ«IDã«å¤‰æ›
        let actualModelId = getModelId(for: model)
        print("Loading model: \(model) (actual ID: \(actualModelId))")
        
        // æœ€å¤§3å›ã¾ã§å†è©¦è¡Œ
        var retryCount = 0
        let maxRetries = 3
        
        while retryCount < maxRetries && modelState != .loaded {
            do {
                if retryCount > 0 {
                    print("Retrying model loading (attempt \(retryCount + 1)/\(maxRetries))")
                    optimizationStatus = "Retrying model loading (attempt \(retryCount + 1)/\(maxRetries))"
                    try await Task.sleep(nanoseconds: 1_000_000_000) // 1ç§’å¾…æ©Ÿ
                }
                
                var folder: URL?
                
                // ã¾ãšã‚¢ãƒ—ãƒªãƒãƒ³ãƒ‰ãƒ«å†…ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
                var bundlePath: String?
                
                // å…ƒã®ãƒ¢ãƒ‡ãƒ«IDã¾ãŸã¯è¡¨ç¤ºåã§ãƒãƒ³ãƒ‰ãƒ«ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’æ¤œç´¢
                // Bundle.main.path()ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨
                if let path = Bundle.main.path(forResource: model, ofType: nil) {
                    bundlePath = path
                    print("Found bundled model via Bundle.main.path (display name): \(path)")
                } else if let path = Bundle.main.path(forResource: actualModelId, ofType: nil) {
                    bundlePath = path
                    print("Found bundled model via Bundle.main.path (ID): \(path)")
                } else if let url = Bundle.main.url(forResource: model, withExtension: nil) {
                    bundlePath = url.path
                    print("Found bundled model via Bundle.main.url (display name): \(url.path)")
                } else if let url = Bundle.main.url(forResource: actualModelId, withExtension: nil) {
                    bundlePath = url.path
                    print("Found bundled model via Bundle.main.url (ID): \(url.path)")
                }
                
                // ãƒãƒ³ãƒ‰ãƒ«ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®è¿½åŠ æ¤œç´¢
                if bundlePath == nil {
                    print("Bundled model not found via Bundle APIs, trying direct paths")
                    
                    // 1. bundlePathå†…ã‚’æ¤œç´¢
                    let bundleMainPath = Bundle.main.bundlePath
                    let modelIdPath = "\(bundleMainPath)/\(actualModelId)"
                    let displayNamePath = "\(bundleMainPath)/\(model)"
                    
                    if FileManager.default.fileExists(atPath: displayNamePath) {
                        bundlePath = displayNamePath
                        print("Found bundled model by display name: \(displayNamePath)")
                    } else if FileManager.default.fileExists(atPath: modelIdPath) {
                        bundlePath = modelIdPath
                        print("Found bundled model by ID: \(modelIdPath)")
                    }
                    
                    // 2. resourcePathå†…ã‚’æ¤œç´¢
                    if bundlePath == nil, let resourcePath = Bundle.main.resourcePath {
                        let resourceModelPath = "\(resourcePath)/\(model)"
                        let resourceModelIdPath = "\(resourcePath)/\(actualModelId)"
                        
                        if FileManager.default.fileExists(atPath: resourceModelPath) {
                            bundlePath = resourceModelPath
                            print("Found bundled model in Resources by display name: \(resourceModelPath)")
                        } else if FileManager.default.fileExists(atPath: resourceModelIdPath) {
                            bundlePath = resourceModelIdPath
                            print("Found bundled model in Resources by ID: \(resourceModelIdPath)")
                        }
                    }
                    
                    // 3. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®Resourcesãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¤œç´¢
                    if bundlePath == nil {
                        let projectPaths = [
                            "\(bundleMainPath)/../Cription/Resources/\(model)",
                            "\(bundleMainPath)/../../Cription/Resources/\(model)",
                            "\(bundleMainPath)/../../../Cription/Resources/\(model)",
                            "\(bundleMainPath)/../Cription/Resources/\(actualModelId)",
                            "\(bundleMainPath)/../../Cription/Resources/\(actualModelId)",
                            "\(bundleMainPath)/../../../Cription/Resources/\(actualModelId)"
                        ]
                        
                        for path in projectPaths {
                            let normalizedPath = (path as NSString).standardizingPath
                            if FileManager.default.fileExists(atPath: normalizedPath) {
                                bundlePath = normalizedPath
                                print("Found bundled model in project Resources: \(normalizedPath)")
                                break
                            }
                        }
                    }
                }
                
                if let bundlePath = bundlePath {
                    // ãƒãƒ³ãƒ‰ãƒ«ãƒ¢ãƒ‡ãƒ«ã®æ•´åˆæ€§ã‚’ãƒã‚§ãƒƒã‚¯
                    if await validateModelFiles(at: URL(fileURLWithPath: bundlePath)) {
                        folder = URL(fileURLWithPath: bundlePath)
                        optimizationStatus = "Loading bundled model"
                        optimizationProgress = 0.1
                        print("Using bundled model at: \(bundlePath)")
                    } else {
                        throw NSError(domain: "WhisperModelManager", code: 6, userInfo: [NSLocalizedDescriptionKey: "Bundled model files are corrupted or incomplete"])
                    }
                }
                // ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆå…ƒã®ãƒ¢ãƒ‡ãƒ«IDã§æ¤œç´¢ï¼‰
                else if localModels.contains(actualModelId) && !redownload {
                    // ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½¿ç”¨
                    if let documents = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask).first {
                        let modelPath = documents.appendingPathComponent("huggingface/models/argmaxinc/whisperkit-coreml").appendingPathComponent(actualModelId)
                        
                        // ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´åˆæ€§ã‚’ãƒã‚§ãƒƒã‚¯
                        if await validateModelFiles(at: modelPath) {
                            folder = modelPath
                            optimizationStatus = "Loading local model"
                            optimizationProgress = 0.1
                        } else {
                            // ç ´æã—ãŸãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¦å†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                            optimizationStatus = "Corrupted model detected, re-downloading"
                            optimizationProgress = 0.0
                            await deleteModelFiles(actualModelId)
                            // å†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«é€²ã‚€
                        }
                    }
                }
                
                // OpenAIãƒ¢ãƒ‡ãƒ«ã®å ´åˆã¯WhisperKitã®ãƒ­ãƒ¼ãƒ‰ã‚’ã‚¹ã‚­ãƒƒãƒ—
                if isOpenAIModel(model) {
                    print("OpenAI model detected: \(model) - skipping WhisperKit model loading")
                    modelState = .loaded
                    optimizationProgress = 1.0
                    optimizationStatus = "OpenAI model ready"
                    print("OpenAI model setup completed successfully")
                    break // æˆåŠŸã—ãŸã‚‰ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹
                }
                // ãƒãƒ³ãƒ‰ãƒ«ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®å ´åˆã¯ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’ã‚¹ã‚­ãƒƒãƒ—
                else if folder == nil && !isBundledModel(model) {
                    // ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆå…ƒã®ãƒ¢ãƒ‡ãƒ«IDã‚’ä½¿ç”¨ï¼‰
                    folder = try await WhisperKit.download(variant: actualModelId, from: repoName) { progress in
                        Task { @MainActor in
                            self.optimizationProgress = progress.fractionCompleted * 0.6
                            self.optimizationStatus = "Downloading model \(Int(progress.fractionCompleted * 100))%"
                        }
                    }
                } else if folder == nil && isBundledModel(model) {
                    // ãƒãƒ³ãƒ‰ãƒ«ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ã‚¨ãƒ©ãƒ¼
                    throw NSError(domain: "WhisperModelManager", code: 2, userInfo: [NSLocalizedDescriptionKey: "Bundled model '\(model)' (ID: \(actualModelId)) not found in app bundle"])
                }
                
                modelState = .downloaded
                optimizationProgress = 0.6
                optimizationStatus = "Initializing WhisperKit"
                
                // WhisperKitã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
                let config = WhisperKitConfig(
                    computeOptions: getComputeOptions(),
                    verbose: false,
                    logLevel: .error,
                    prewarm: false,
                    load: false,
                    download: false
                )
                
                // ãƒ‡ãƒã‚¤ã‚¹è­˜åˆ¥ã®ãƒ­ã‚°ã‚’æŠ‘åˆ¶
                setupWhisperKitLogging()
                
                do {
                    whisperKit = try await WhisperKit(config)
                    whisperKit?.modelFolder = folder
                    
                    // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚¿ã‚¹ã‚¯è¨­å®šã‚’å¼·åˆ¶çš„ã«tranCriptionã«è¨­å®š
                    print("ğŸ”§ Setting default task to tranCription mode (auto load)")
                    // WhisperKitã®å†…éƒ¨è¨­å®šã¯DecodingOptionsã§åˆ¶å¾¡
                    print("âœ… WhisperKit default task will be set via DecodingOptions")
                } catch {
                    // WhisperKitã®åˆæœŸåŒ–ã«å¤±æ•—ã—ãŸå ´åˆã€ç ´æã—ãŸãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¦å†è©¦è¡Œ
                    optimizationStatus = "Model initialization failed, cleaning up"
                    optimizationProgress = 0.0
                    await deleteModelFiles(model)
                    throw error
                }
                
                if let modelFolder = folder {
                    whisperKit?.modelFolder = modelFolder
                    
                    modelState = .prewarming
                    optimizationProgress = 0.7
                    optimizationStatus = "Optimizing model"
                    
                    // ãƒ¢ãƒ‡ãƒ«ã‚’æœ€é©åŒ–ï¼ˆprewarmï¼‰
                    try await whisperKit?.prewarmModels()
                    
                    modelState = .loading
                    optimizationProgress = 0.8
                    optimizationStatus = "Loading model"
                    
                    // ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
                    try await whisperKit?.loadModels()
                    
                    modelState = .loaded
                    optimizationProgress = 1.0
                    optimizationStatus = "Model ready"
                    
                    // ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆã«è¿½åŠ ï¼ˆå…ƒã®ãƒ¢ãƒ‡ãƒ«IDï¼‰
                    if !localModels.contains(actualModelId) {
                        localModels.append(actualModelId)
                    }
                    
                    print("Model loading completed successfully")
                    break // æˆåŠŸã—ãŸã‚‰ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹
                }
                
            } catch {
                retryCount += 1
                print("Model loading failed (attempt \(retryCount)/\(maxRetries)): \(error.localizedDescription)")
                
                if retryCount >= maxRetries {
                    modelState = .unloaded
                    optimizationStatus = "Load failed after \(maxRetries) attempts: \(error.localizedDescription)"
                    print("All retry attempts exhausted. Manual model selection required.")
                } else {
                    optimizationStatus = "Retrying in a moment (attempt \(retryCount)/\(maxRetries))"
                    modelState = .unloaded
                }
            }
        }
    }
    
    // è‡ªå‹•ãƒ‡ãƒã‚¤ã‚¹æœ€é©åŒ–ãƒ»ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½
    @MainActor
    func autoOptimizeAndLoadModel() async {
        print("ğŸ”„ Starting autoOptimizeAndLoadModel")
        print("ğŸ”„ Current model state: \(modelState)")
        print("ğŸ”„ Selected model: \(selectedModel)")
        print("ğŸ”„ Local models: \(localModels)")
        
        guard !isOptimizing else { 
            print("âš ï¸ Auto-optimization already in progress, skipping")
            return 
        }
        
        // OpenAIãƒ¢ãƒ‡ãƒ«ãŒé¸æŠã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€WhisperKitãƒ¢ãƒ‡ãƒ«ã®è‡ªå‹•ãƒ­ãƒ¼ãƒ‰ã‚’ã‚¹ã‚­ãƒƒãƒ—
        if selectedModel == "whisper-1" || selectedModel == "gpt-4o-mini-transcribe" || selectedModel == "gpt-4o-transcribe" {
            print("ğŸ”„ OpenAI model selected (\(selectedModel)), skipping WhisperKit auto-load")
            optimizationStatus = "OpenAI model selected - WhisperKit auto-load skipped"
            return
        }
        
        // ã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ã¯åˆ¶é™è§£é™¤ï¼‰
        let subscriptionManager = SubCriptionManager.shared
        
        // ãƒãƒ³ãƒ‰ãƒ«ãƒ¢ãƒ‡ãƒ«ä»¥å¤–ã§ã€ã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ãŒãªã„å ´åˆã¯è‡ªå‹•ãƒ­ãƒ¼ãƒ‰ä¸å¯ï¼ˆOpenAIãƒ¢ãƒ‡ãƒ«ã®ã¿ï¼‰
        if !isBundledModel(selectedModel) && isOpenAIModel(selectedModel) && !subscriptionManager.isSubCriptiond {
            print("âŒ Subscription required for model: \(selectedModel)")
            optimizationStatus = "Subscription required to use this model"
            return
        }
        
        guard !localModels.isEmpty else {
            print("âŒ No bundled models found in localModels, cannot auto-load")
            print("âŒ Available local models: \(localModels)")
            optimizationStatus = "Bundled model not available for auto-loading"
            return
        }
        
        print("âœ… \(localModels.count) bundled models found, proceeding with auto-load")
        isOptimizing = true
        optimizationProgress = 0.0
        optimizationStatus = "Initializing automatic model setup"
        
        // æœ€å¤§3å›ã¾ã§å†è©¦è¡Œ
        var retryCount = 0
        let maxRetries = 3
        
        while retryCount < maxRetries && modelState != .loaded {
            do {
                if retryCount > 0 {
                    print("Retrying model loading (attempt \(retryCount + 1)/\(maxRetries))")
                    optimizationStatus = "Retrying model loading (attempt \(retryCount + 1)/\(maxRetries))"
                    try await Task.sleep(nanoseconds: 1_000_000_000) // 1ç§’å¾…æ©Ÿ
                }
                
                print("Starting automatic model optimization and loading")
                
                // ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±ã‚’å–å¾—
                let deviceInfo = getDeviceInfo()
                optimizationStatus = "Analyzing device capabilities"
                optimizationProgress = 0.1
                logMessage("Device info: \(deviceInfo.model), Memory: \(deviceInfo.availableMemory / (1024*1024*1024))GB")
                
                // æœ€é©ãªãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’æ±ºå®š
                let optimalConfig = determineOptimalConfig(for: deviceInfo)
                optimizationStatus = "Configuring optimal settings"
                optimizationProgress = 0.2
                logMessage("Optimal config: GPU=\(optimalConfig.enableGPUAcceleration), Quantized=\(optimalConfig.useQuantizedModel)")
                
                // ãƒ¢ãƒ‡ãƒ«æœ€é©åŒ–ã‚’å®Ÿè¡Œ
                optimizationStatus = "Optimizing model for device"
                optimizationProgress = 0.3
                
                // ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã•ã‚ŒãŸæœ€é©åŒ–å‡¦ç†
                try await performModelOptimization(config: optimalConfig)
                
                optimizationStatus = "Model optimization completed"
                optimizationProgress = 0.4
                logMessage("Model optimization completed successfully")
                
                // æœ€é©åŒ–å®Œäº†å¾Œã€å°‘ã—å¾…ã£ã¦ã‹ã‚‰ãƒ­ãƒ¼ãƒ‰é–‹å§‹
                try await Task.sleep(nanoseconds: 500_000_000) // 0.5ç§’
                
                // è‡ªå‹•ãƒ­ãƒ¼ãƒ‰ã‚’é–‹å§‹
                optimizationStatus = "Loading \(selectedModelDisplayName)"
                optimizationProgress = 0.5
                logMessage("Starting model loading")
                
                // è‡ªå‹•ãƒ­ãƒ¼ãƒ‰å‡¦ç†ã‚’å®Ÿè¡Œ
                try await performAutoLoad()
                
                // ãƒ¢ãƒ‡ãƒ«ãŒå®Ÿéš›ã«ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸã‹ç¢ºèª
                if modelState == .loaded && whisperKit != nil {
                    optimizationStatus = "Model ready for use"
                    optimizationProgress = 1.0
                    print("Model loading completed successfully!")
                    print("WhisperKit instance: \(whisperKit != nil ? "Ready" : "Not ready")")
                    print("Model state: \(modelState)")
                    
                    // å®Œäº†å¾Œã€å°‘ã—å¾…ã£ã¦ã‹ã‚‰ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ã‚¯ãƒªã‚¢
                    try await Task.sleep(nanoseconds: 2_000_000_000) // 2ç§’
                    optimizationStatus = ""
                    print("âœ¨ Auto-optimization and loading completed!")
                    break // æˆåŠŸã—ãŸã‚‰ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹
                } else {
                    throw NSError(domain: "WhisperModelManager", code: 3, userInfo: [NSLocalizedDescriptionKey: "Model loading completed but state is not loaded"])
                }
                
            } catch {
                retryCount += 1
                print("Auto-load failed (attempt \(retryCount)/\(maxRetries)): \(error.localizedDescription)")
                
                if retryCount >= maxRetries {
                    optimizationStatus = "Auto-load failed after \(maxRetries) attempts: \(error.localizedDescription)"
                    modelState = .unloaded
                    print("All retry attempts exhausted. Manual model selection required.")
                } else {
                    optimizationStatus = "Retrying in a moment (attempt \(retryCount)/\(maxRetries))"
                    modelState = .unloaded
                }
            }
        }
        
        isOptimizing = false
    }
    
    // è‡ªå‹•ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½
    private func performAutoLoad() async throws {
        optimizationStatus = "Locating bundled model"
        optimizationProgress = 0.6
        
        // ã‚¢ãƒ—ãƒªãƒãƒ³ãƒ‰ãƒ«å†…ã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚©ãƒ«ãƒ€ã‚’å–å¾—
        guard let bundlePath = findBundledModelPath() else {
            optimizationStatus = "Bundled model not found in app bundle"
            print("âŒ Bundled model not found, attempting alternative search")
            
            // ä»£æ›¿æ¤œç´¢ã‚’è©¦è¡Œ
            let alternativePath = Bundle.main.path(forResource: "Cription mini", ofType: nil)
            if let altPath = alternativePath {
                print("âœ… Found alternative bundled model path: \(altPath)")
                return try await loadBundledModel(from: altPath)
            }
            
            throw NSError(domain: "WhisperModelManager", code: 1, userInfo: [NSLocalizedDescriptionKey: "Bundled model 'Cription mini' not found in app bundle"])
        }
        
        print("ğŸ“ Using bundled model at: \(bundlePath)")
        return try await loadBundledModel(from: bundlePath)
    }
    
    // ãƒãƒ³ãƒ‰ãƒ«ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰å‡¦ç†ã‚’å…±é€šåŒ–
    private func loadBundledModel(from bundlePath: String) async throws {
        let folder = URL(fileURLWithPath: bundlePath)
        
        // ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚©ãƒ«ãƒ€ã®å­˜åœ¨ã¨æ•´åˆæ€§ã‚’ç¢ºèª
        guard FileManager.default.fileExists(atPath: bundlePath) else {
            throw NSError(domain: "WhisperModelManager", code: 2, userInfo: [NSLocalizedDescriptionKey: "Model folder does not exist at path: \(bundlePath)"])
        }
        
        // ãƒãƒ³ãƒ‰ãƒ«ãƒ¢ãƒ‡ãƒ«ã®æ•´åˆæ€§ã‚’ãƒã‚§ãƒƒã‚¯
        guard await validateModelFiles(at: URL(fileURLWithPath: bundlePath)) else {
            throw NSError(domain: "WhisperModelManager", code: 7, userInfo: [NSLocalizedDescriptionKey: "Bundled model files are corrupted or incomplete at path: \(bundlePath)"])
        }
        
        optimizationStatus = "Initializing WhisperKit"
        optimizationProgress = 0.7
        
        // WhisperKitã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        let config = WhisperKitConfig(
            computeOptions: getComputeOptions(),
            verbose: false,
            logLevel: .error,
            prewarm: false,
            load: false,
            download: false
        )
        
        // ãƒ‡ãƒã‚¤ã‚¹è­˜åˆ¥ã®ãƒ­ã‚°ã‚’æŠ‘åˆ¶
        setupWhisperKitLogging()
        
                whisperKit = try await WhisperKit(config)
                whisperKit?.modelFolder = folder
                
                // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚¿ã‚¹ã‚¯è¨­å®šã‚’å¼·åˆ¶çš„ã«tranCriptionã«è¨­å®š
                print("ğŸ”§ Setting default task to tranCription mode")
                // WhisperKitã®å†…éƒ¨è¨­å®šã¯DecodingOptionsã§åˆ¶å¾¡
                print("âœ… WhisperKit default task will be set via DecodingOptions")
        
        // WhisperKitã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒæ­£å¸¸ã«ä½œæˆã•ã‚ŒãŸã‹ç¢ºèª
        guard whisperKit != nil else {
            throw NSError(domain: "WhisperModelManager", code: 4, userInfo: [NSLocalizedDescriptionKey: "Failed to create WhisperKit instance"])
        }
        
        optimizationStatus = "Warming up model"
        optimizationProgress = 0.8
        
        // ãƒ¢ãƒ‡ãƒ«ã‚’æœ€é©åŒ–ï¼ˆprewarmï¼‰
        try await whisperKit?.prewarmModels()
        
        optimizationStatus = "Loading model"
        optimizationProgress = 0.9
        
        // ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
        try await whisperKit?.loadModels()
        
        // ãƒ¢ãƒ‡ãƒ«ãŒå®Ÿéš›ã«ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸã‹æœ€çµ‚ç¢ºèª
        guard whisperKit?.modelState == .loaded else {
            let errorMsg = "Model loading completed but WhisperKit model state is not loaded"
            print("âŒ \(errorMsg)")
            print("âŒ WhisperKit model state: \(whisperKit?.modelState ?? .unloaded)")
            throw NSError(domain: "WhisperModelManager", code: 5, userInfo: [NSLocalizedDescriptionKey: errorMsg])
        }
        
        modelState = .loaded
        optimizationStatus = "Model ready for use!"
        optimizationProgress = 1.0
        print("âœ… Model loaded successfully and ready for tranCription!")
        print("âœ… Model state: \(whisperKit?.modelState ?? .unloaded)")
        print("âœ… Selected model: \(selectedModel)")
        print("âœ… Auto-load completed successfully")
    }
    
    // ãƒãƒ³ãƒ‰ãƒ«ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹ã‚’æ¤œç´¢ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
    private func findBundledModelPath() -> String? {
        print("Searching for bundled model path")
        
        // ãƒãƒ³ãƒ‰ãƒ«ãƒ‘ã‚¹ã‚’ä¸€åº¦ã ã‘å–å¾—
        let bundlePath = Bundle.main.bundlePath
        
        // ãƒãƒ³ãƒ‰ãƒ«ã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã®æƒ…å ±ï¼ˆãƒ¢ãƒ‡ãƒ«IDã¨è¡¨ç¤ºåï¼‰
        let bundledModelInfo: [(id: String, displayName: String)] = [
            ("openai_whisper-base", "Cription mini"),
            ("openai_whisper-tiny.en", "Cription Swift English"),
            ("openai_whisper-base.en", "Cription mini English")
        ]
        
        // 1. Bundle.main.path(forResource:ofType:)ã‚’ä½¿ç”¨ã—ãŸæ¤œç´¢ï¼ˆæœ€å„ªå…ˆï¼‰
        for modelInfo in bundledModelInfo {
            // è¡¨ç¤ºåã§æ¤œç´¢
            if let modelPath = Bundle.main.path(forResource: modelInfo.displayName, ofType: nil) {
                print("Found bundled model by display name: \(modelInfo.displayName) at \(modelPath)")
                return modelPath
            }
            
            // ãƒ¢ãƒ‡ãƒ«IDã§æ¤œç´¢
            if let modelPath = Bundle.main.path(forResource: modelInfo.id, ofType: nil) {
                print("Found bundled model by ID: \(modelInfo.id) at \(modelPath)")
                return modelPath
            }
        }
        
        // 2. Resourcesãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç›´æ¥æ¤œç´¢
        if let resourcePath = Bundle.main.resourcePath {
            for modelInfo in bundledModelInfo {
                // è¡¨ç¤ºåã§æ¤œç´¢
                let displayNamePath = "\(resourcePath)/\(modelInfo.displayName)"
                if FileManager.default.fileExists(atPath: displayNamePath) {
                    print("Found bundled model in Resources: \(modelInfo.displayName) at \(displayNamePath)")
                    return displayNamePath
                }
                
                // ãƒ¢ãƒ‡ãƒ«IDã§æ¤œç´¢
                let modelIdPath = "\(resourcePath)/\(modelInfo.id)"
                if FileManager.default.fileExists(atPath: modelIdPath) {
                    print("Found bundled model in Resources: \(modelInfo.id) at \(modelIdPath)")
                    return modelIdPath
                }
            }
        }
        
        // 3. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®Resourcesãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¤œç´¢
        for modelInfo in bundledModelInfo {
            let projectPaths = [
                "\(bundlePath)/../Cription/Resources/\(modelInfo.displayName)",
                "\(bundlePath)/../../Cription/Resources/\(modelInfo.displayName)",
                "\(bundlePath)/../../../Cription/Resources/\(modelInfo.displayName)",
                "\(bundlePath)/../Cription/Resources/\(modelInfo.id)",
                "\(bundlePath)/../../Cription/Resources/\(modelInfo.id)",
                "\(bundlePath)/../../../Cription/Resources/\(modelInfo.id)"
            ]
            
            for path in projectPaths {
                let normalizedPath = (path as NSString).standardizingPath
                if FileManager.default.fileExists(atPath: normalizedPath) {
                    print("Found bundled model in project Resources: \(normalizedPath)")
                    return normalizedPath
                }
            }
        }
        
        // 4. ã‚ˆã‚Šè©³ç´°ãªæ¤œç´¢ - ãƒãƒ³ãƒ‰ãƒ«å†…å®¹ã‚’åˆ—æŒ™
        print("Bundled model not found, checking bundle contents")
        if let resourcePath = Bundle.main.resourcePath {
            do {
                let contents = try FileManager.default.contentsOfDirectory(atPath: resourcePath)
                print("Bundle contents: \(contents)")
                
                // ãƒ¢ãƒ‡ãƒ«åã‚’å«ã‚€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¤œç´¢
                for content in contents {
                    for modelInfo in bundledModelInfo {
                        if content.contains(modelInfo.displayName) || content.contains(modelInfo.id) {
                            let fullPath = "\(resourcePath)/\(content)"
                            if FileManager.default.fileExists(atPath: fullPath) {
                                print("Found potential model directory: \(fullPath)")
                                return fullPath
                            }
                        }
                    }
                }
            } catch {
                print("Error reading bundle contents: \(error)")
            }
        }
        
        // 2. ãƒãƒ³ãƒ‰ãƒ«ãƒ‘ã‚¹ç›´ä¸‹ã‚’æ¤œç´¢
        for modelInfo in bundledModelInfo {
            let displayNamePath = "\(bundlePath)/\(modelInfo.displayName)"
            if FileManager.default.fileExists(atPath: displayNamePath) {
                print("Found bundled model: \(modelInfo.displayName) at \(displayNamePath)")
                return displayNamePath
            }
            
            let modelIdPath = "\(bundlePath)/\(modelInfo.id)"
            if FileManager.default.fileExists(atPath: modelIdPath) {
                print("Found bundled model: \(modelInfo.id) at \(modelIdPath)")
                return modelIdPath
            }
        }
        
        // 3. Bundle APIã‚’ä½¿ç”¨ã—ãŸæ¤œç´¢
        for modelInfo in bundledModelInfo {
            if let path = Bundle.main.path(forResource: modelInfo.displayName, ofType: nil) {
                print("Found bundled model via path: \(path)")
                return path
            }
            
            if let path = Bundle.main.path(forResource: modelInfo.id, ofType: nil) {
                print("Found bundled model via path: \(path)")
                return path
            }
        }
        
        // 4. URLãƒ™ãƒ¼ã‚¹ã®æ¤œç´¢
        for modelInfo in bundledModelInfo {
            if let url = Bundle.main.url(forResource: modelInfo.displayName, withExtension: nil) {
                print("Found bundled model via URL: \(url.path)")
                return url.path
            }
            
            if let url = Bundle.main.url(forResource: modelInfo.id, withExtension: nil) {
                print("Found bundled model via URL: \(url.path)")
                return url.path
            }
        }
        
        // 5. ã‚ˆã‚Šè©³ç´°ãªæ¤œç´¢
        print("Bundled model not found, checking bundle contents")
        let bundleResources = Bundle.main.paths(forResourcesOfType: nil, inDirectory: nil)
        
        // ãƒãƒ³ãƒ‰ãƒ«å†…ã®ãƒªã‚½ãƒ¼ã‚¹ã‹ã‚‰ç›´æ¥æ¤œç´¢
        for resource in bundleResources {
            for modelInfo in bundledModelInfo {
                if resource.contains(modelInfo.displayName) || resource.contains(modelInfo.id) {
                    print("Found bundled model in resources: \(resource)")
                    return resource
                }
            }
        }
        
        print("Bundled model not found in any location")
        return nil
    }
    
    // ãƒãƒ³ãƒ‰ãƒ«ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯
    private func isBundledModel(_ model: String) -> Bool {
        // OpenAIãƒ¢ãƒ‡ãƒ«ã®å ´åˆã¯ãƒãƒ³ãƒ‰ãƒ«ãƒ¢ãƒ‡ãƒ«ã§ã¯ãªã„
        if isOpenAIModel(model) {
            return false
        }
        
        // ãƒ¢ãƒ‡ãƒ«åâ†’IDã®ãƒãƒƒãƒ”ãƒ³ã‚°
        let modelToId: [String: String] = [
            "Cription Swift English": "openai_whisper-tiny.en",
            "Cription mini": "openai_whisper-base",
            "Cription mini English": "openai_whisper-base.en"
        ]
        
        // å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«IDã‚’å–å¾—
        let actualModelId = modelToId[model] ?? model
        
        // ãƒãƒ³ãƒ‰ãƒ«ãƒ‘ã‚¹ã‚’å–å¾—
        let bundlePath = Bundle.main.bundlePath
        
        // 1. Resourcesãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç›´æ¥æ¤œç´¢ï¼ˆæœ€å„ªå…ˆï¼‰
        if let resourcePath = Bundle.main.resourcePath {
            let resourceModelPath = "\(resourcePath)/\(model)"
            let resourceModelIdPath = "\(resourcePath)/\(actualModelId)"
            
            if FileManager.default.fileExists(atPath: resourceModelPath) {
                print("Found bundled model in Resources: \(resourceModelPath)")
                return true
            }
            
            if FileManager.default.fileExists(atPath: resourceModelIdPath) {
                print("Found bundled model in Resources: \(resourceModelIdPath)")
                return true
            }
        }
        
        // 1.5. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®Resourcesãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¤œç´¢
        let projectPaths = [
            "\(bundlePath)/../Cription/Resources/\(model)",
            "\(bundlePath)/../../Cription/Resources/\(model)",
            "\(bundlePath)/../../../Cription/Resources/\(model)",
            "\(bundlePath)/../Cription/Resources/\(actualModelId)",
            "\(bundlePath)/../../Cription/Resources/\(actualModelId)",
            "\(bundlePath)/../../../Cription/Resources/\(actualModelId)"
        ]
        
        for path in projectPaths {
            let normalizedPath = (path as NSString).standardizingPath
            if FileManager.default.fileExists(atPath: normalizedPath) {
                print("Found bundled model in project Resources: \(normalizedPath)")
                return true
            }
        }
        
        // 2. ãƒãƒ³ãƒ‰ãƒ«ãƒ‘ã‚¹å†…ã‚’ç›´æ¥æ¤œç´¢
        let modelPath = "\(bundlePath)/\(model)"
        let modelIdPath = "\(bundlePath)/\(actualModelId)"
        
        if FileManager.default.fileExists(atPath: modelPath) {
            print("Found bundled model at direct path: \(modelPath)")
            return true
        }
        
        if FileManager.default.fileExists(atPath: modelIdPath) {
            print("Found bundled model at direct path: \(modelIdPath)")
            return true
        }
        
        // 3. Bundle APIã§æ¤œç´¢
        if let path = Bundle.main.path(forResource: model, ofType: nil) {
            print("Found bundled model via path: \(path)")
            return true
        }
        
        if let path = Bundle.main.path(forResource: actualModelId, ofType: nil) {
            print("Found bundled model via path: \(path)")
            return true
        }
        
        // 4. URLãƒ™ãƒ¼ã‚¹ã®æ¤œç´¢
        if let url = Bundle.main.url(forResource: model, withExtension: nil) {
            print("Found bundled model via URL: \(url.path)")
            return true
        }
        
        if let url = Bundle.main.url(forResource: actualModelId, withExtension: nil) {
            print("Found bundled model via URL: \(url.path)")
            return true
        }
        
        // 5. ãƒãƒ³ãƒ‰ãƒ«ãƒªã‚½ãƒ¼ã‚¹ã‹ã‚‰æ¤œç´¢
        let bundleResources = Bundle.main.paths(forResourcesOfType: nil, inDirectory: nil)
        for resource in bundleResources {
            if resource.contains(model) || resource.contains(actualModelId) {
                print("Found bundled model in resources: \(resource)")
                return true
            }
        }
        
        // 6. ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆã‹ã‚‰æ¤œç´¢ï¼ˆãƒãƒ³ãƒ‰ãƒ«ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦è¿½åŠ ã•ã‚ŒãŸã‚‚ã®ï¼‰
        if localModels.contains(model) || localModels.contains(actualModelId) {
            print("Found model in localModels: \(model)")
            return true
        }
        
        print("Model \(model) not found as bundled model")
        return false
    }
    
    // OpenAIãƒ¢ãƒ‡ãƒ«ã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯
    private func isOpenAIModel(_ model: String) -> Bool {
        return model == "whisper-1" || model == "gpt-4o-transcribe" || model == "gpt-4o-mini-transcribe"
    }
    
    private func getComputeOptions() -> ModelComputeOptions {
        // ãƒ‡ãƒã‚¤ã‚¹ã«åŸºã¥ã„ã¦æœ€é©ãªè¨ˆç®—ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’æ±ºå®š
        #if os(iOS)
        let isLowPowerMode = ProcessInfo.processInfo.isLowPowerModeEnabled
        if isLowPowerMode {
            return ModelComputeOptions(
                melCompute: .cpuOnly,
                audioEncoderCompute: .cpuOnly,
                textDecoderCompute: .cpuOnly,
                prefillCompute: .cpuOnly
            )
        } else {
            return ModelComputeOptions(
                melCompute: .cpuAndNeuralEngine,
                audioEncoderCompute: .cpuAndNeuralEngine,
                textDecoderCompute: .cpuAndNeuralEngine,
                prefillCompute: .cpuAndNeuralEngine
            )
        }
        #else
        return ModelComputeOptions(
            melCompute: .cpuAndGPU,
            audioEncoderCompute: .cpuAndGPU,
            textDecoderCompute: .cpuAndGPU,
            prefillCompute: .cpuAndGPU
        )
        #endif
    }
    
    // ãƒ‡ãƒã‚¤ã‚¹è­˜åˆ¥ã®ãƒ­ã‚°å‡ºåŠ›ã‚’åˆ¶å¾¡ã™ã‚‹ãŸã‚ã®ã‚«ã‚¹ã‚¿ãƒ ãƒ­ã‚°ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
    private func setupCustomLogging() {
        // WhisperKitã®ãƒ­ã‚°ã¯WhisperKitConfigã§åˆ¶å¾¡
        // ãƒ‡ãƒã‚¤ã‚¹è­˜åˆ¥ã®é‡è¤‡ãƒ­ã‚°ã¯verbose: falseã¨logLevel: .errorã§æŠ‘åˆ¶
        print("ğŸ”§ WhisperKit logging configured to suppress device identification messages")
    }
    
    // WhisperKitã®ãƒ­ã‚°è¨­å®šã‚’æœ€é©åŒ–
    private func setupWhisperKitLogging() {
        // WhisperKitã®ãƒ­ã‚°ã¯WhisperKitConfigã§åˆ¶å¾¡
        // ãƒ‡ãƒã‚¤ã‚¹è­˜åˆ¥ã®é‡è¤‡ãƒ­ã‚°ã¯verbose: falseã¨logLevel: .errorã§æŠ‘åˆ¶
        print("ğŸ”§ WhisperKit logging configured to suppress device identification messages")
    }
    
    // ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
    private static var cachedDeviceInfo: DeviceInfo?
    
    // ãƒ­ã‚°å‡ºåŠ›ã®é‡è¤‡é˜²æ­¢
    private static var lastLogMessage: String = ""
    private static var logRepeatCount: Int = 0
    
    private func getDeviceInfo() -> DeviceInfo {
        // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸãƒ‡ãƒã‚¤ã‚¹æƒ…å ±ãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ç”¨
        if let cached = Self.cachedDeviceInfo {
            return cached
        }
        
        #if os(iOS)
        let deviceModel = UIDevice.current.model
        let systemVersion = UIDevice.current.systemVersion
        let isLowPowerModeEnabled = ProcessInfo.processInfo.isLowPowerModeEnabled
        #else
        let deviceModel = "Mac"
        let systemVersion = ProcessInfo.processInfo.operatingSystemVersionString
        let isLowPowerModeEnabled = false
        #endif
        
        let deviceInfo = DeviceInfo(
            model: deviceModel,
            systemVersion: systemVersion,
            isLowPowerMode: isLowPowerModeEnabled,
            availableMemory: getAvailableMemory()
        )
        
        // ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        Self.cachedDeviceInfo = deviceInfo
        return deviceInfo
    }
    
    // é‡è¤‡ãƒ­ã‚°ã‚’é˜²ããƒ­ã‚°å‡ºåŠ›æ©Ÿèƒ½
    private func logMessage(_ message: String) {
        if Self.lastLogMessage == message {
            Self.logRepeatCount += 1
            if Self.logRepeatCount <= 3 {
                print("\(message) (repeated \(Self.logRepeatCount) times)")
            }
        } else {
            if Self.logRepeatCount > 0 {
                print("\(Self.lastLogMessage) (repeated \(Self.logRepeatCount) times total)")
            }
            print(message)
            Self.lastLogMessage = message
            Self.logRepeatCount = 0
        }
    }
    
    private func getAvailableMemory() -> UInt64 {
        var info = mach_task_basic_info()
        var count = mach_msg_type_number_t(MemoryLayout<mach_task_basic_info>.size)/4
        
        let kerr: kern_return_t = withUnsafeMutablePointer(to: &info) {
            $0.withMemoryRebound(to: integer_t.self, capacity: 1) {
                task_info(mach_task_self_,
                         task_flavor_t(MACH_TASK_BASIC_INFO),
                         $0,
                         &count)
            }
        }
        
        if kerr == KERN_SUCCESS {
            return info.resident_size
        } else {
            return 0
        }
    }
    
    private func determineOptimalConfig(for deviceInfo: DeviceInfo) -> OptimizationConfig {
        // ãƒ‡ãƒã‚¤ã‚¹ã«åŸºã¥ã„ã¦æœ€é©ãªè¨­å®šã‚’æ±ºå®š
        let availableMemoryGB = Double(deviceInfo.availableMemory) / (1024 * 1024 * 1024)
        
        if deviceInfo.isLowPowerMode || availableMemoryGB < 2.0 {
            // ä½é›»åŠ›ãƒ¢ãƒ¼ãƒ‰ã¾ãŸã¯ãƒ¡ãƒ¢ãƒªä¸è¶³ã®å ´åˆ
            return OptimizationConfig(
                useQuantizedModel: true,
                maxConcurrentTasks: 1,
                enableGPUAcceleration: false,
                memoryOptimization: .aggressive
            )
        } else if availableMemoryGB >= 8.0 {
            // é«˜ãƒ¡ãƒ¢ãƒªãƒ‡ãƒã‚¤ã‚¹ã®å ´åˆ
            return OptimizationConfig(
                useQuantizedModel: false,
                maxConcurrentTasks: 4,
                enableGPUAcceleration: true,
                memoryOptimization: .standard
            )
        } else {
            // æ¨™æº–ãƒ‡ãƒã‚¤ã‚¹ã®å ´åˆ
            return OptimizationConfig(
                useQuantizedModel: false,
                maxConcurrentTasks: 2,
                enableGPUAcceleration: true,
                memoryOptimization: .standard
            )
        }
    }
    
    private func performModelOptimization(config: OptimizationConfig) async throws {
        // å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ã“ã“ã§WhisperKitã®æœ€é©åŒ–APIã‚’å‘¼ã³å‡ºã™
        // ç¾åœ¨ã¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã—ã¦éåŒæœŸå‡¦ç†ã‚’å®Ÿè¡Œ
        
        optimizationStatus = "Loading model components"
        optimizationProgress = 0.7
        
        try await Task.sleep(nanoseconds: 1_000_000_000) // 1ç§’
        
        optimizationStatus = "Applying optimizations"
        optimizationProgress = 0.8
        
        try await Task.sleep(nanoseconds: 1_000_000_000) // 1ç§’
        
        optimizationStatus = "Finalizing configuration"
        optimizationProgress = 0.9
        
        try await Task.sleep(nanoseconds: 500_000_000) // 0.5ç§’
    }
    
}

// MARK: - Supporting Types

struct DeviceInfo {
    let model: String
    let systemVersion: String
    let isLowPowerMode: Bool
    let availableMemory: UInt64
}

struct OptimizationConfig {
    let useQuantizedModel: Bool
    let maxConcurrentTasks: Int
    let enableGPUAcceleration: Bool
    let memoryOptimization: MemoryOptimizationLevel
}

enum MemoryOptimizationLevel {
    case standard
    case aggressive
}

