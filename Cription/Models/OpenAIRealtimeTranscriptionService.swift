//  For licensing see accompanying LICENSE.md file.
//  Copyright Â© 2025 Cription. All rights reserved.

import Foundation
import SwiftUI
import AVFoundation

// MARK: - OpenAI Realtime Transcription Service (Official API with Delta Events)

@MainActor
class OpenAIRealtimeTranscriptionService: NSObject, ObservableObject {
    @Published var isRecording = false
    @Published var realtimeText: String = ""
    @Published var error: String?
    @Published var audioSamples: [Float] = []
    
    private let apiKey: String
    private let baseURL = "wss://api.openai.com/v1/realtime"
    private let subscriptionManager = SubCriptionManager()
    private var webSocketTask: URLSessionWebSocketTask?
    private var audioEngine: AVAudioEngine?
    private var inputNode: AVAudioInputNode?
    private var currentModel: String = "gpt-4o-mini-transcribe"
    private var currentLanguage: String?
    private var sessionReady = false
    private var isConnected = false
    private let connectionTimeout: TimeInterval = 30.0
    private let maxRetryAttempts: Int = 3
    private var retryCount: Int = 0
    private var waveformSamples: [Float] = []
    private let maxWaveformSamples = 1000
    
    init(apiKey: String) {
        self.apiKey = apiKey
        super.init()
    }
    
    // MARK: - Public Methods
    
    func startRealtimeTranscription(model: String = "gpt-4o-mini-transcribe", language: String? = nil) async throws {
        guard !isRecording else {
            throw TranCriptionError.alreadyProcessing
        }
        
        // ã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³åˆ¶é™ãƒã‚§ãƒƒã‚¯
        guard subscriptionManager.canUseOpenAITranCription() else {
            throw TranCriptionError.subscriptionLimitExceeded
        }
        
        // ãƒ¢ãƒ‡ãƒ«ã‚¢ã‚¯ã‚»ã‚¹åˆ¶é™ãƒã‚§ãƒƒã‚¯
        guard subscriptionManager.canUseCloudModel(model) else {
            throw TranCriptionError.modelAccessDenied
        }
        
        currentModel = model
        currentLanguage = language
        sessionReady = false
        error = nil
        retryCount = 0
        realtimeText = "Connecting..."
        
        print("âœ… Starting realtime transcription with delta events")
        print("   - Model: \(currentModel)")
        print("   - Language: \(language ?? "auto")")
        print("   - Delta behavior: \(currentModel == "whisper-1" ? "Full transcript" : "Incremental")")
        
        // ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãã§WebSocketæ¥ç¶šã‚’ç¢ºç«‹
        do {
            try await connectWebSocketWithRetry()
        } catch {
            print("âŒ Failed to establish WebSocket connection after retries")
            throw error
        }
        
        // ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒæº–å‚™å®Œäº†ã™ã‚‹ã¾ã§å¾…æ©Ÿ
        let startTime = Date()
        while !sessionReady && isConnected && error == nil {
            if Date().timeIntervalSince(startTime) > connectionTimeout {
                print("âŒ Session setup timeout after \(connectionTimeout)s")
                throw TranCriptionError.apiError(408, "Session setup timeout")
            }
            try await Task.sleep(nanoseconds: 100_000_000) // 100mså¾…æ©Ÿ
        }
        
        // ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯ä¾‹å¤–ã‚’ã‚¹ãƒ­ãƒ¼
        if let errorMessage = error {
            throw TranCriptionError.apiError(400, errorMessage)
        }
        
        // æ¥ç¶šãŒåˆ‡æ–­ã•ã‚ŒãŸå ´åˆ
        if !isConnected {
            throw TranCriptionError.apiError(0, "Connection lost")
        }
        
        print("âœ… Session ready, starting audio capture")
        
        // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªéŒ²éŸ³ã‚’é–‹å§‹
        try await startAudioCapture()
        
        isRecording = true
        realtimeText = "Listening..."
    }
    
    func stopRealtimeTranscription() async {
        isRecording = false
        sessionReady = false
        
        // ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆæ¶ˆè²»ï¼ˆéŒ²éŸ³æ™‚é–“ã‚’æ¨å®šï¼‰
        let estimatedDuration = Double(audioSamples.count) / 16000.0 // 16kHzã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ
        if estimatedDuration > 0 {
            let success = subscriptionManager.consumeAPICredits(
                duration: estimatedDuration,
                model: currentModel,
                isTranslation: false
            )
            
            if !success {
                error = "Insufficient credits for realtime transcription"
            }
        }
        
        // æ³¢å½¢ã‚µãƒ³ãƒ—ãƒ«ã‚’ã‚¯ãƒªã‚¢
        waveformSamples = []
        audioSamples = []
        
        // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªéŒ²éŸ³ã‚’åœæ­¢
        stopAudioCapture()
        
        // WebSocketæ¥ç¶šã‚’åˆ‡æ–­
        disconnectWebSocket()
    }
    
    // MARK: - Private Methods - WebSocket
    
    private func connectWebSocketWithRetry() async throws {
        for attempt in 1...maxRetryAttempts {
            do {
                print("ğŸ”„ Connection attempt \(attempt)/\(maxRetryAttempts)")
                try await connectWebSocket()
                return // æˆåŠŸã—ãŸå ´åˆã¯çµ‚äº†
            } catch {
                print("âŒ Connection attempt \(attempt) failed: \(error.localizedDescription)")
                
                if attempt < maxRetryAttempts {
                    let delay = TimeInterval(attempt * 2) // æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
                    print("â³ Retrying in \(delay) seconds...")
                    try await Task.sleep(nanoseconds: UInt64(delay * 1_000_000_000))
                } else {
                    print("âŒ All connection attempts failed")
                    throw error
                }
            }
        }
    }
    
    private func connectWebSocket() async throws {
        // Realtime APIå¯¾å¿œãƒ¢ãƒ‡ãƒ«ã«ãƒãƒƒãƒ”ãƒ³ã‚°
        let realtimeModelMapping: [String: String] = [
            "whisper-1": "gpt-4o-realtime-preview-2024-12-17",
            "gpt-4o-transcribe": "gpt-4o-realtime-preview-2024-12-17", 
            "gpt-4o-mini-transcribe": "gpt-4o-mini-realtime-preview-2024-12-17"
        ]
        
        let realtimeModel = realtimeModelMapping[currentModel] ?? "gpt-4o-realtime-preview-2024-12-17"
        
        print("ğŸ”— WebSocket connection initiated")
        print("   - User selected model: \(currentModel)")
        print("   - Mapped to realtime model: \(realtimeModel)")
        
        guard let url = URL(string: "\(baseURL)?model=\(realtimeModel)") else {
            throw TranCriptionError.invalidURL
        }
        
        var request = URLRequest(url: url)
        request.setValue("Bearer \(apiKey)", forHTTPHeaderField: "Authorization")
        request.setValue("realtime=v1", forHTTPHeaderField: "OpenAI-Beta")
        request.timeoutInterval = connectionTimeout
        
        // WebSocketå°‚ç”¨ã®è¨­å®š
        let config = URLSessionConfiguration.default
        config.timeoutIntervalForRequest = connectionTimeout
        config.timeoutIntervalForResource = connectionTimeout
        
        let session = URLSession(configuration: config, delegate: self, delegateQueue: OperationQueue())
        webSocketTask = session.webSocketTask(with: request)
        webSocketTask?.resume()
        
        print("   - URL: \(url)")
        print("   - Timeout: \(connectionTimeout)s")
        
        // æ¥ç¶šå®Œäº†ã‚’å¾…æ©Ÿ
        let startTime = Date()
        while !isConnected && Date().timeIntervalSince(startTime) < connectionTimeout {
            try await Task.sleep(nanoseconds: 50_000_000) // 50mså¾…æ©Ÿ
        }
        
        guard isConnected else {
            throw TranCriptionError.apiError(408, "WebSocket connection timeout")
        }
        
        print("âœ… WebSocket connected successfully")
        
        // WebSocketãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å—ä¿¡ãƒ«ãƒ¼ãƒ—ã‚’é–‹å§‹
        Task {
            await receiveMessages()
        }
        
        // ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®šã‚’é€ä¿¡
        try await sendSessionConfig()
    }
    
    private func disconnectWebSocket() {
        webSocketTask?.cancel(with: .goingAway, reason: nil)
        webSocketTask = nil
        isConnected = false
    }
    
    private func sendSessionConfig() async throws {
        // æœ€å°é™ã®è¨­å®šã§ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼ã‚’å›é¿
        let sessionUpdate: [String: Any] = [
            "type": "session.update",
            "session": [
                "modalities": ["text"],
                "input_audio_format": "pcm16"
            ]
        ]
        
        let jsonData = try JSONSerialization.data(withJSONObject: sessionUpdate)
        let message = URLSessionWebSocketTask.Message.data(jsonData)
        try await webSocketTask?.send(message)
        
        print("âœ… Session config sent (minimal format)")
        print("   - User model: \(currentModel)")
        print("   - Config: \(String(data: jsonData, encoding: .utf8) ?? "N/A")")
    }
    
    private func receiveMessages() async {
        guard let webSocketTask = webSocketTask else { return }
        
        do {
            while isConnected {
                let message = try await webSocketTask.receive()
                
                switch message {
                case .data(let data):
                    await handleMessage(data: data)
                case .string(let text):
                    if let data = text.data(using: .utf8) {
                        await handleMessage(data: data)
                    }
                @unknown default:
                    break
                }
            }
        } catch {
            print("âŒ WebSocket receive error: \(error.localizedDescription)")
            await MainActor.run {
                self.error = "WebSocket error: \(error.localizedDescription)"
                self.isConnected = false
                self.sessionReady = false
            }
        }
    }
    
    private func handleMessage(data: Data) async {
        do {
            guard let json = try JSONSerialization.jsonObject(with: data) as? [String: Any],
                  let type = json["type"] as? String else {
                print("âš ï¸ Failed to parse message type")
                return
            }
            
            print("ğŸ“© Received message type: \(type)")
            
            switch type {
            case "session.created":
                print("âœ… Session created")
                await MainActor.run {
                    self.realtimeText = "Connecting..."
                }
                
            case "session.updated":
                print("âœ… Session updated - ready for audio")
                await MainActor.run {
                    self.sessionReady = true
                    self.realtimeText = "Ready..."
                }
                
            case "response.audio_transcript.delta":
                // å…¬å¼ã®deltaã‚¤ãƒ™ãƒ³ãƒˆï¼šéƒ¨åˆ†çš„ãªè»¢å†™çµæœ
                if let delta = json["delta"] as? String {
                    print("ğŸ“ Delta: \(delta)")
                    await MainActor.run {
                        if self.realtimeText == "Listening..." || self.realtimeText == "Ready..." {
                            self.realtimeText = delta
                        } else {
                            self.realtimeText += delta
                        }
                    }
                }
                
            case "response.audio_transcript.done":
                // å…¬å¼ã®completedã‚¤ãƒ™ãƒ³ãƒˆï¼šæœ€çµ‚çš„ãªè»¢å†™çµæœ
                if let transcript = json["transcript"] as? String {
                    print("âœ… Transcription completed: \(transcript)")
                    await MainActor.run {
                        self.realtimeText = transcript
                    }
                }
                
            case "response.done":
                // å…¬å¼ã®å®Œäº†ã‚¤ãƒ™ãƒ³ãƒˆ
                if let response = json["response"] as? [String: Any],
                   let status = response["status"] as? String,
                   status == "failed",
                   let statusDetails = response["status_details"] as? [String: Any],
                   let error = statusDetails["error"] as? [String: Any],
                   let errorMessage = error["message"] as? String {
                    print("âŒ Response failed: \(errorMessage)")
                    await MainActor.run {
                        self.error = "Response failed: \(errorMessage)"
                    }
                }
                
            case "error":
                if let errorInfo = json["error"] as? [String: Any],
                   let message = errorInfo["message"] as? String {
                    print("âŒ Realtime API Error: \(message)")
                    await MainActor.run {
                        self.error = message
                        self.sessionReady = false
                        self.isConnected = false
                    }
                    
                    // ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤ã‚’åœæ­¢
                    if message.contains("server had an error") || message.contains("internal server error") {
                        print("âŒ Server error detected, stopping automatic reconnection")
                        print("   - This appears to be a server-side issue with OpenAI's Realtime API")
                        print("   - Please try again later or contact OpenAI support")
                    }
                }
                
            case "input_audio_buffer.speech_started":
                print("ğŸ¤ Speech started")
                await MainActor.run {
                    self.realtimeText = "Listening..."
                }
                
            case "input_audio_buffer.speech_stopped":
                print("ğŸ¤ Speech stopped")
                
            case "response.audio.delta":
                // éŸ³å£°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®deltaï¼ˆé€šå¸¸ã¯è»¢å†™ã§ã¯ä½¿ç”¨ã—ãªã„ï¼‰
                print("ğŸ”Š Audio delta received")
                
            case "response.audio.done":
                // éŸ³å£°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å®Œäº†ï¼ˆé€šå¸¸ã¯è»¢å†™ã§ã¯ä½¿ç”¨ã—ãªã„ï¼‰
                print("ğŸ”Š Audio response completed")
                
            default:
                print("â„¹ï¸ Unhandled message type: \(type)")
                if let jsonString = String(data: data, encoding: .utf8) {
                    print("   Full message: \(jsonString)")
                }
            }
        } catch {
            print("âŒ Failed to parse message: \(error.localizedDescription)")
            await MainActor.run {
                self.error = "Failed to parse message: \(error.localizedDescription)"
            }
        }
    }
    
    // MARK: - Private Methods - Audio
    
    private func startAudioCapture() async throws {
        audioEngine = AVAudioEngine()
        guard let audioEngine = audioEngine else {
            throw TranCriptionError.invalidAudioData
        }
        
        inputNode = audioEngine.inputNode
        guard let inputNode = inputNode else {
            throw TranCriptionError.invalidAudioData
        }
        
        let recordingFormat = inputNode.outputFormat(forBus: 0)
        
        // 24kHz, mono, PCM16ã«å¤‰æ›ã™ã‚‹ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆOpenAI Realtime APIè¦ä»¶ï¼‰
        guard let targetFormat = AVAudioFormat(
            commonFormat: .pcmFormatInt16,
            sampleRate: 24000,
            channels: 1,
            interleaved: false
        ) else {
            throw TranCriptionError.invalidAudioData
        }
        
        guard let converter = AVAudioConverter(from: recordingFormat, to: targetFormat) else {
            throw TranCriptionError.invalidAudioData
        }
        
        inputNode.installTap(onBus: 0, bufferSize: 4096, format: recordingFormat) { [weak self] buffer, _ in
            guard let self = self else { return }
            
            Task { @MainActor in
                do {
                    // ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒæº–å‚™å®Œäº†ã—ã¦ã„ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                    guard self.sessionReady else {
                        return
                    }
                    
                    // PCMãƒãƒƒãƒ•ã‚¡ã‚’å¤‰æ›
                    let frameCount = AVAudioFrameCount(Double(buffer.frameLength) * targetFormat.sampleRate / recordingFormat.sampleRate)
                    guard let convertedBuffer = AVAudioPCMBuffer(pcmFormat: targetFormat, frameCapacity: frameCount) else {
                        return
                    }
                    
                    var error: NSError?
                    let status = converter.convert(to: convertedBuffer, error: &error) { _, outStatus in
                        outStatus.pointee = .haveData
                        return buffer
                    }
                    
                    if status == .error, let error = error {
                        print("âŒ Audio conversion error: \(error.localizedDescription)")
                        self.error = "Audio conversion error: \(error.localizedDescription)"
                        return
                    }
                    
                    // æ³¢å½¢è¡¨ç¤ºç”¨ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’æ›´æ–°
                    self.updateWaveformSamples(from: convertedBuffer)
                    
                    // PCM16ãƒ‡ãƒ¼ã‚¿ã‚’WebSocketã§é€ä¿¡
                    try await self.sendAudioData(buffer: convertedBuffer)
                    
                } catch {
                    print("âŒ Audio processing error: \(error.localizedDescription)")
                }
            }
        }
        
        try audioEngine.start()
    }
    
    private func stopAudioCapture() {
        inputNode?.removeTap(onBus: 0)
        audioEngine?.stop()
        audioEngine = nil
        inputNode = nil
    }
    
    private func updateWaveformSamples(from buffer: AVAudioPCMBuffer) {
        guard let channelData = buffer.int16ChannelData else { return }
        
        let frameLength = Int(buffer.frameLength)
        let samples = Array(UnsafeBufferPointer(start: channelData[0], count: frameLength))
        
        // Int16ã‚µãƒ³ãƒ—ãƒ«ã‚’Floatã«å¤‰æ›ã—ã¦æ³¢å½¢è¡¨ç¤ºç”¨ã«è¿½åŠ 
        let floatSamples = samples.map { Float($0) / Float(Int16.max) }
        
        waveformSamples.append(contentsOf: floatSamples)
        
        // æœ€å¤§ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’è¶…ãˆãŸå ´åˆã¯å¤ã„ã‚µãƒ³ãƒ—ãƒ«ã‚’å‰Šé™¤
        if waveformSamples.count > maxWaveformSamples {
            let removeCount = waveformSamples.count - maxWaveformSamples
            waveformSamples.removeFirst(removeCount)
        }
        
        // ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã§UIã‚’æ›´æ–°
        Task { @MainActor in
            self.audioSamples = self.waveformSamples
        }
    }
    
    private func sendAudioData(buffer: AVAudioPCMBuffer) async throws {
        // WebSocketãŒæ¥ç¶šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
        guard let webSocketTask = webSocketTask, 
              webSocketTask.state == .running else {
            return
        }
        
        // ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒæº–å‚™å®Œäº†ã—ã¦ã„ã‚‹ã‹ç¢ºèª
        guard sessionReady else {
            return
        }
        
        guard let channelData = buffer.int16ChannelData else {
            return
        }
        
        let frameLength = Int(buffer.frameLength)
        let data = Data(bytes: channelData[0], count: frameLength * MemoryLayout<Int16>.size)
        
        // Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        let base64Audio = data.base64EncodedString()
        
        let message: [String: Any] = [
            "type": "input_audio_buffer.append",
            "audio": base64Audio
        ]
        
        let jsonData = try JSONSerialization.data(withJSONObject: message)
        let webSocketMessage = URLSessionWebSocketTask.Message.data(jsonData)
        
        do {
            try await webSocketTask.send(webSocketMessage)
        } catch {
            print("âŒ Failed to send audio data: \(error.localizedDescription)")
            await MainActor.run {
                self.error = "Failed to send audio: \(error.localizedDescription)"
            }
        }
    }
}

// MARK: - URLSessionWebSocketDelegate

extension OpenAIRealtimeTranscriptionService: URLSessionWebSocketDelegate {
    nonisolated func urlSession(_ session: URLSession, webSocketTask: URLSessionWebSocketTask, didOpenWithProtocol protocol: String?) {
        Task { @MainActor in
            print("âœ… WebSocket connection opened")
            self.isConnected = true
        }
    }
    
    nonisolated func urlSession(_ session: URLSession, webSocketTask: URLSessionWebSocketTask, didCloseWith closeCode: URLSessionWebSocketTask.CloseCode, reason: Data?) {
        Task { @MainActor in
            print("âŒ WebSocket connection closed: \(closeCode)")
            self.isConnected = false
            self.sessionReady = false
        }
    }
    
    nonisolated func urlSession(_ session: URLSession, task: URLSessionTask, didCompleteWithError error: Error?) {
        if let error = error {
            Task { @MainActor in
                print("âŒ WebSocket error: \(error.localizedDescription)")
                self.error = "WebSocket error: \(error.localizedDescription)"
                self.isConnected = false
                self.sessionReady = false
            }
        }
    }
}